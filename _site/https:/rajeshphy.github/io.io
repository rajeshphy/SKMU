<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en-US"><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/SKMU/https:/rajeshphy.github/io" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/SKMU/" rel="alternate" type="text/html" hreflang="en-US" /><updated>2025-05-20T15:22:30+05:30</updated><id>http://localhost:4000/SKMU/https:/rajeshphy.github/io</id><title type="html">Rajesh Kumar</title><subtitle>Lecture Notes</subtitle><author><name>Rajesh Kumar</name></author><entry><title type="html">Hamiltonâ€“Jacobi Equation</title><link href="http://localhost:4000/SKMU/lecture/2025/05/20/H-J-Theory.html" rel="alternate" type="text/html" title="Hamiltonâ€“Jacobi Equation" /><published>2025-05-20T09:47:26+05:30</published><updated>2025-05-20T09:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/20/H-J-Theory</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/20/H-J-Theory.html">&lt;h2 id=&quot;hamiltonjacobi-equation-with-example-of-harmonic-oscillator&quot;&gt;Hamiltonâ€“Jacobi Equation with Example of Harmonic Oscillator&lt;/h2&gt;

&lt;p&gt;&lt;span style=&quot;color:darkred&quot;&gt;&lt;strong&gt;Learning Objectives&lt;/strong&gt;&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the formulation and significance of the Hamiltonâ€“Jacobi equation in classical mechanics.&lt;/li&gt;
  &lt;li&gt;Learn how to reduce the problem of solving equations of motion to solving a partial differential equation.&lt;/li&gt;
  &lt;li&gt;Apply the Hamiltonâ€“Jacobi method to solve the harmonic oscillator problem.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hamiltonâ€“Jacobi Equation&lt;/strong&gt;: A first-order partial differential equation for the action function $S(q, t)$ derived from Hamiltonâ€™s equations.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Action Function ($S$)&lt;/strong&gt;: A function whose complete solution generates the equations of motion via canonical transformation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Harmonic Oscillator&lt;/strong&gt;: A system in which a particle experiences a restoring force proportional to its displacement.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Hamiltonâ€“Jacobi equation (HJE)&lt;/strong&gt; is an alternative formulation of classical mechanics that can be used to solve the equations of motion by solving a partial differential equation. It is especially powerful because it reduces the problem of dynamics to integration.&lt;/p&gt;

&lt;p&gt;The central idea is to find a generating function $S(q, t)$ such that the transformation to new coordinates results in constant generalized momenta. This function $S$ satisfies the Hamiltonâ€“Jacobi equation:&lt;/p&gt;

\[\frac{\partial S}{\partial t} + H\left(q, \frac{\partial S}{\partial q}, t\right) = 0\]

&lt;p&gt;If $S(q, t)$ is known, then the equations of motion can be obtained by simple differentiation, and the trajectories can be determined directly.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Let the Hamiltonian of a system be:&lt;/p&gt;

\[H(q, p, t)\]

&lt;p&gt;We define the action function $S(q, \alpha, t)$, where $\alpha$ are constants of integration. The canonical momentum is:&lt;/p&gt;

\[p_i = \frac{\partial S}{\partial q_i}\]

&lt;p&gt;Then the &lt;strong&gt;Hamiltonâ€“Jacobi equation&lt;/strong&gt; is:&lt;/p&gt;

\[\frac{\partial S}{\partial t} + H\left(q, \frac{\partial S}{\partial q}, t\right) = 0\]

&lt;p&gt;For &lt;strong&gt;time-independent systems&lt;/strong&gt;, we use &lt;strong&gt;separation of variables&lt;/strong&gt;:&lt;/p&gt;

\[S(q, t) = W(q) - Et\]

&lt;p&gt;Substituting into HJE gives:&lt;/p&gt;

\[H\left(q, \frac{\partial W}{\partial q}\right) = E\]

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Derive the Hamiltonâ€“Jacobi equation for a 1D harmonic oscillator and find the action function.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;The Hamiltonian of a 1D harmonic oscillator is:&lt;/p&gt;

\[H = \frac{p^2}{2m} + \frac{1}{2} m \omega^2 q^2\]

    &lt;p&gt;Assume $S(q, t) = W(q) - Et$, then the time-independent HJE becomes:&lt;/p&gt;

\[\frac{1}{2m} \left( \frac{dW}{dq} \right)^2 + \frac{1}{2} m \omega^2 q^2 = E\]

    &lt;p&gt;Solving:&lt;/p&gt;

\[\left( \frac{dW}{dq} \right)^2 = 2m \left( E - \frac{1}{2} m \omega^2 q^2 \right)\]

\[\frac{dW}{dq} = \sqrt{2mE - m^2 \omega^2 q^2}\]

    &lt;p&gt;Integrating:&lt;/p&gt;

\[W(q) = \int \sqrt{2mE - m^2 \omega^2 q^2} \, dq\]

    &lt;p&gt;Let $A^2 = \frac{2E}{m \omega^2}$, then:&lt;/p&gt;

\[W(q) = \frac{E}{\omega} \arcsin \left( \frac{q}{A} \right) + \frac{m \omega}{2} q \sqrt{A^2 - q^2}\]

    &lt;p&gt;Hence, the full action is:&lt;/p&gt;

\[S(q, t) = W(q) - Et\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Using the Hamiltonâ€“Jacobi method, find the trajectory of a particle in a harmonic oscillator potential.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;From the previous example, we know $S(q, t) = W(q) - Et$.&lt;/p&gt;

    &lt;p&gt;From the Hamiltonâ€“Jacobi method:&lt;/p&gt;

\[\frac{\partial S}{\partial E} = \text{constant} = \beta\]

    &lt;p&gt;So,&lt;/p&gt;

\[\frac{\partial W}{\partial E} - t = \beta\]

    &lt;p&gt;Using $W(q)$ from before:&lt;/p&gt;

\[\frac{\partial W}{\partial E} = \frac{1}{\omega} \arcsin \left( \frac{q}{A} \right)\]

    &lt;p&gt;Therefore:&lt;/p&gt;

\[\frac{1}{\omega} \arcsin \left( \frac{q}{A} \right) - t = \beta \Rightarrow \frac{q}{A} = \sin(\omega t + \phi)\]

    &lt;p&gt;Thus, the trajectory is:&lt;/p&gt;

\[q(t) = A \sin(\omega t + \phi)\]

    &lt;p&gt;which is the expected solution for a harmonic oscillator.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The Hamiltonâ€“Jacobi equation provides a powerful method to solve mechanical problems using partial differential equations.&lt;/li&gt;
  &lt;li&gt;It can simplify finding trajectories, especially for integrable systems.&lt;/li&gt;
  &lt;li&gt;For time-independent systems, separation of variables is often applicable.&lt;/li&gt;
  &lt;li&gt;In the harmonic oscillator, the HJE approach reproduces the sinusoidal motion.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Short Answer&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;What is the physical interpretation of the action function $S(q, t)$ in the Hamiltonâ€“Jacobi theory?&lt;/li&gt;
      &lt;li&gt;How does the Hamiltonâ€“Jacobi equation relate to canonical transformations?&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Derive the Hamiltonâ€“Jacobi equation for a free particle in 1D.&lt;/li&gt;
      &lt;li&gt;Find the generating function $S(q, t)$ for a particle in a uniform gravitational field.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MCQs&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;The Hamiltonâ€“Jacobi equation transforms the problem of motion into solving:
        &lt;ul&gt;
          &lt;li&gt;a) A linear equation&lt;/li&gt;
          &lt;li&gt;b) A second-order ODE&lt;/li&gt;
          &lt;li&gt;c) A first-order PDE&lt;/li&gt;
          &lt;li&gt;d) A matrix equation&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: c)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;In the Hamiltonâ€“Jacobi method, if $S = W(q) - Et$, the function $W(q)$ is known as:
        &lt;ul&gt;
          &lt;li&gt;a) Hamiltonian&lt;/li&gt;
          &lt;li&gt;b) Characteristic function&lt;/li&gt;
          &lt;li&gt;c) Action-angle function&lt;/li&gt;
          &lt;li&gt;d) Phase function&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: b)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">Hamiltonâ€“Jacobi Equation with Example of Harmonic Oscillator</summary></entry><entry><title type="html">Hamilton Equation of Motion</title><link href="http://localhost:4000/SKMU/lecture/2025/05/20/Hamilton-Equation.html" rel="alternate" type="text/html" title="Hamilton Equation of Motion" /><published>2025-05-20T09:10:26+05:30</published><updated>2025-05-20T09:10:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/20/Hamilton-Equation</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/20/Hamilton-Equation.html">&lt;h1 id=&quot;hamiltons-equations-of-motion&quot;&gt;Hamiltonâ€™s Equations of Motion&lt;/h1&gt;

&lt;p&gt;&lt;span style=&quot;color:darkred&quot;&gt;&lt;strong&gt;Learning Objectives&lt;/strong&gt;&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the formulation of Hamiltonian mechanics from Lagrangian mechanics.&lt;/li&gt;
  &lt;li&gt;Learn how to derive Hamiltonâ€™s equations of motion.&lt;/li&gt;
  &lt;li&gt;Apply Hamiltonian formalism to simple mechanical systems.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hamiltonian ($H$)&lt;/strong&gt;: A function usually representing the total energy of a system, obtained via Legendre transformation of the Lagrangian.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Generalized Coordinates ($q_i$)&lt;/strong&gt;: Variables that describe the configuration of a system.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Generalized Momenta ($p_i$)&lt;/strong&gt;: Conjugate momenta defined as $p_i = \frac{\partial L}{\partial \dot{q}_i}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Hamiltonian mechanics is an alternative formulation of classical mechanics that uses generalized coordinates $q_i$ and conjugate momenta $p_i$ instead of just coordinates and velocities.&lt;/p&gt;

&lt;p&gt;Given the Lagrangian $L(q_i, \dot{q}_i, t)$, the conjugate momenta are defined as:&lt;/p&gt;

\[p_i = \frac{\partial L}{\partial \dot{q}_i}\]

&lt;p&gt;The Hamiltonian $H$ is defined as the Legendre transform of the Lagrangian:&lt;/p&gt;

\[H(q_i, p_i, t) = \sum_i p_i \dot{q}_i - L(q_i, \dot{q}_i, t)\]

&lt;p&gt;Hamiltonâ€™s equations of motion are the following first-order differential equations:&lt;/p&gt;

\[\dot{q}_i = \frac{\partial H}{\partial p_i}, \quad \dot{p}_i = -\frac{\partial H}{\partial q_i}\]

&lt;p&gt;These equations describe the time evolution of a system in phase space and form the basis of modern theoretical physics, including quantum mechanics and statistical mechanics.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Starting with the Lagrangian $L(q_i, \dot{q}_i, t)$, define the conjugate momenta:&lt;/p&gt;

\[p_i = \frac{\partial L}{\partial \dot{q}_i}\]

&lt;p&gt;Perform a Legendre transformation to obtain the Hamiltonian:&lt;/p&gt;

\[H(q_i, p_i, t) = \sum_i p_i \dot{q}_i - L\]

&lt;p&gt;Then Hamiltonâ€™s equations of motion follow as:&lt;/p&gt;

\[\dot{q}_i = \frac{\partial H}{\partial p_i}, \quad \dot{p}_i = -\frac{\partial H}{\partial q_i}\]

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Derive Hamiltonâ€™s equations for a free particle of mass $m$.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
Lagrangian:&lt;/p&gt;

\[L = \frac{1}{2} m \dot{q}^2\]

    &lt;p&gt;Conjugate momentum:&lt;/p&gt;

\[p = \frac{\partial L}{\partial \dot{q}} = m \dot{q} \Rightarrow \dot{q} = \frac{p}{m}\]

    &lt;p&gt;Hamiltonian:&lt;/p&gt;

\[H = p \dot{q} - L = \frac{p^2}{m} - \frac{1}{2} m \left( \frac{p}{m} \right)^2 = \frac{p^2}{2m}\]

    &lt;p&gt;Hamiltonâ€™s equations:&lt;/p&gt;

\[\dot{q} = \frac{\partial H}{\partial p} = \frac{p}{m}, \quad \dot{p} = -\frac{\partial H}{\partial q} = 0\]

    &lt;p&gt;Hence, the particle moves with constant momentum.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Apply Hamiltonâ€™s equations to a simple harmonic oscillator.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
Lagrangian:&lt;/p&gt;

\[L = \frac{1}{2} m \dot{q}^2 - \frac{1}{2} k q^2\]

    &lt;p&gt;Conjugate momentum:&lt;/p&gt;

\[p = \frac{\partial L}{\partial \dot{q}} = m \dot{q} \Rightarrow \dot{q} = \frac{p}{m}\]

    &lt;p&gt;Hamiltonian:&lt;/p&gt;

\[H = \frac{p^2}{2m} + \frac{1}{2} k q^2\]

    &lt;p&gt;Hamiltonâ€™s equations:&lt;/p&gt;

\[\dot{q} = \frac{\partial H}{\partial p} = \frac{p}{m}, \quad \dot{p} = -\frac{\partial H}{\partial q} = -k q\]

    &lt;p&gt;These yield the standard equations of motion for a harmonic oscillator.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hamiltonian mechanics provides a symmetrical, phase-space-based approach to classical mechanics.&lt;/li&gt;
  &lt;li&gt;The Hamiltonian often corresponds to the total energy.&lt;/li&gt;
  &lt;li&gt;Hamiltonâ€™s equations are first-order and are useful in analytical and quantum mechanics.&lt;/li&gt;
  &lt;li&gt;Canonical transformations preserve the form of Hamiltonâ€™s equations.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Short Answer&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Define the Hamiltonian and explain how it is related to the Lagrangian.&lt;/li&gt;
      &lt;li&gt;Write down Hamiltonâ€™s equations for a charged particle in an electromagnetic field.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Derive the Hamiltonian for a particle of mass $m$ in a potential $V(q) = \lambda q^4$.&lt;/li&gt;
      &lt;li&gt;Compute $\dot{q}$ and $\dot{p}$ for a particle in the potential $V(q) = \frac{1}{2}kq^2$ using Hamiltonâ€™s equations.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MCQs&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Hamiltonâ€™s equations are:
        &lt;ul&gt;
          &lt;li&gt;a) Second-order equations in time&lt;/li&gt;
          &lt;li&gt;b) First-order equations in time&lt;/li&gt;
          &lt;li&gt;c) Algebraic equations&lt;/li&gt;
          &lt;li&gt;d) None of the above&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: b)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The Hamiltonian for a free particle is:
        &lt;ul&gt;
          &lt;li&gt;a) $H = \frac{p^2}{2m}$&lt;/li&gt;
          &lt;li&gt;b) $H = \frac{1}{2} m q^2$&lt;/li&gt;
          &lt;li&gt;c) $H = p q$&lt;/li&gt;
          &lt;li&gt;d) $H = m p$&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: a)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">Hamiltonâ€™s Equations of Motion</summary></entry><entry><title type="html">Hamiltonâ€™s Principle</title><link href="http://localhost:4000/SKMU/lecture/2025/05/20/Hamilton-Principle.html" rel="alternate" type="text/html" title="Hamilton&apos;s Principle" /><published>2025-05-20T07:47:26+05:30</published><updated>2025-05-20T07:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/20/Hamilton-Principle</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/20/Hamilton-Principle.html">&lt;h2 id=&quot;hamiltons-principle&quot;&gt;Hamiltonâ€™s Principle&lt;/h2&gt;

&lt;p&gt;&lt;span style=&quot;color:darkred&quot;&gt;&lt;strong&gt;Learning Objectives&lt;/strong&gt;&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the statement and physical meaning of Hamiltonâ€™s principle.&lt;/li&gt;
  &lt;li&gt;Derive the Euler-Lagrange equations from the principle.&lt;/li&gt;
  &lt;li&gt;Apply Hamiltonâ€™s principle to solve simple dynamical systems.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hamiltonâ€™s Principle&lt;/strong&gt;: The actual path taken by a system between two configurations is such that the action integral is stationary (usually a minimum).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Action&lt;/strong&gt;: The integral of the Lagrangian over time, $S = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stationary Action&lt;/strong&gt;: A value of the action where its first variation is zero, $\delta S = 0$.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Hamiltonâ€™s Principle, also known as the &lt;strong&gt;Principle of Stationary Action&lt;/strong&gt;, is a cornerstone of analytical mechanics. It states that:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Out of all possible paths that a system can follow between two fixed points in configuration space and time, the actual path followed is the one that makes the action integral stationary.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This principle unifies many laws of classical mechanics and provides a natural route to derive the &lt;strong&gt;Euler-Lagrange equations&lt;/strong&gt;, which are central to Lagrangian mechanics.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;action&lt;/strong&gt; is a scalar quantity defined by:&lt;/p&gt;

\[S[q(t)] = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt\]

&lt;p&gt;Here:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$q(t)$ are generalized coordinates.&lt;/li&gt;
  &lt;li&gt;$\dot{q} = \frac{dq}{dt}$ is the generalized velocity.&lt;/li&gt;
  &lt;li&gt;$L(q, \dot{q}, t)$ is the &lt;strong&gt;Lagrangian&lt;/strong&gt; of the system, typically $T - V$, where $T$ is kinetic energy and $V$ is potential energy.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If the action is stationary, then the path taken by the system satisfies:&lt;/p&gt;

\[\delta S = 0\]

&lt;p&gt;This leads to the Euler-Lagrange equation, which governs the dynamics of the system.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Let $q(t)$ be a differentiable path connecting two fixed endpoints at $t = t_1$ and $t = t_2$.&lt;/p&gt;

&lt;p&gt;The action functional is:&lt;/p&gt;

\[S[q(t)] = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt\]

&lt;p&gt;Consider a variation $q(t) \rightarrow q(t) + \varepsilon \eta(t)$, where $\eta(t_1) = \eta(t_2) = 0$.&lt;/p&gt;

&lt;p&gt;The variation of action is:&lt;/p&gt;

\[\delta S = \frac{d}{d\varepsilon} S[q + \varepsilon \eta] \bigg|_{\varepsilon=0} = \int_{t_1}^{t_2} \left( \frac{\partial L}{\partial q} \eta + \frac{\partial L}{\partial \dot{q}} \dot{\eta} \right) dt\]

&lt;p&gt;Integrating the second term by parts and applying boundary conditions:&lt;/p&gt;

\[\delta S = \int_{t_1}^{t_2} \left( \frac{\partial L}{\partial q} - \frac{d}{dt} \frac{\partial L}{\partial \dot{q}} \right) \eta(t) \, dt\]

&lt;p&gt;For $\delta S = 0$ for arbitrary $\eta(t)$, the integrand must vanish:&lt;/p&gt;

\[\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}} \right) - \frac{\partial L}{\partial q} = 0\]

&lt;p&gt;This is the &lt;strong&gt;Euler-Lagrange equation&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Derive the equation of motion for a free particle using Hamiltonâ€™s principle.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
For a free particle of mass $m$, the Lagrangian is $L = \frac{1}{2} m \dot{x}^2$.&lt;/p&gt;

    &lt;p&gt;Action:
\(S[x(t)] = \int_{t_1}^{t_2} \frac{1}{2} m \dot{x}^2 \, dt\)&lt;/p&gt;

    &lt;p&gt;Euler-Lagrange equation:
\(\frac{d}{dt} \left( m \dot{x} \right) = 0 \Rightarrow m \ddot{x} = 0\)&lt;/p&gt;

    &lt;p&gt;This implies constant velocity motion: $x(t) = vt + c$.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: A particle moves under a constant force $F$. Derive its equation of motion using Hamiltonâ€™s principle.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
The Lagrangian is $L = \frac{1}{2} m \dot{x}^2 + Fx$.&lt;/p&gt;

    &lt;p&gt;Euler-Lagrange equation:
\(\frac{d}{dt}(m \dot{x}) - F = 0 \Rightarrow m \ddot{x} = F\)&lt;/p&gt;

    &lt;p&gt;This leads to uniformly accelerated motion.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hamiltonâ€™s principle leads to the Euler-Lagrange equations.&lt;/li&gt;
  &lt;li&gt;It is a variational reformulation of Newtonian mechanics.&lt;/li&gt;
  &lt;li&gt;The action is stationary, not necessarily minimal.&lt;/li&gt;
  &lt;li&gt;Applies to conservative systems and forms the foundation of field theory.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Short Answer&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;State Hamiltonâ€™s principle in your own words.&lt;/li&gt;
      &lt;li&gt;How is the Euler-Lagrange equation derived from the principle of stationary action?&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;A particle moves under a potential $V(x) = \frac{1}{2} kx^2$. Use Hamiltonâ€™s principle to find the equation of motion.&lt;/li&gt;
      &lt;li&gt;Compute the action for a particle moving from $x=0$ to $x=a$ in time $T$ with constant velocity.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MCQs&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;The Euler-Lagrange equation is obtained from Hamiltonâ€™s principle by:
        &lt;ul&gt;
          &lt;li&gt;a) Differentiating the Lagrangian directly&lt;/li&gt;
          &lt;li&gt;b) Rewriting Newtonâ€™s law&lt;/li&gt;
          &lt;li&gt;c) Requiring $\delta S = 0$ for arbitrary variations&lt;/li&gt;
          &lt;li&gt;d) Using energy conservation&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: c)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;In Hamiltonâ€™s principle, the variation $\eta(t)$ must:
        &lt;ul&gt;
          &lt;li&gt;a) Be arbitrary&lt;/li&gt;
          &lt;li&gt;b) Vanish at the endpoints&lt;/li&gt;
          &lt;li&gt;c) Be a constant function&lt;/li&gt;
          &lt;li&gt;d) Satisfy $\dot{\eta}(t_1) = 0$&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: b)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">Hamiltonâ€™s Principle</summary></entry><entry><title type="html">Least Action Principle</title><link href="http://localhost:4000/SKMU/lecture/2025/05/20/Least-Action.html" rel="alternate" type="text/html" title="Least Action Principle" /><published>2025-05-20T07:46:26+05:30</published><updated>2025-05-20T07:46:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/20/Least-Action</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/20/Least-Action.html">&lt;h1 id=&quot;the-principle-of-least-action&quot;&gt;The Principle of Least Action&lt;/h1&gt;

&lt;p&gt;&lt;span style=&quot;color:darkred&quot;&gt;&lt;strong&gt;Learning Objectives&lt;/strong&gt;&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the physical and mathematical meaning of the principle of least action.&lt;/li&gt;
  &lt;li&gt;Learn how it leads to the Euler-Lagrange equations of motion.&lt;/li&gt;
  &lt;li&gt;Apply the principle to solve simple problems in mechanics.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Action ($S$)&lt;/strong&gt;: A scalar quantity defined as the time integral of the Lagrangian, $S = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt$.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lagrangian ($L$)&lt;/strong&gt;: The function $L = T - V$, where $T$ is kinetic energy and $V$ is potential energy.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Principle of Least Action&lt;/strong&gt;: The path taken by a physical system between two states is the one for which the action is stationary (usually minimized).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;Principle of Least Action&lt;/strong&gt; is a powerful and unifying concept in classical mechanics. It asserts that:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;A system evolves between two configurations in such a way that the action functional $S$ is stationary.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This principle is central to &lt;strong&gt;Lagrangian mechanics&lt;/strong&gt; and underlies modern formulations of physics, including quantum mechanics and field theory.&lt;/p&gt;

&lt;p&gt;Let a mechanical system move from point $A$ at time $t_1$ to point $B$ at time $t_2$. Among all possible paths it could take, the system follows the one for which the action&lt;/p&gt;

\[S[q(t)] = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt\]

&lt;p&gt;is &lt;strong&gt;stationary&lt;/strong&gt; â€” meaning that small variations in the path do not change $S$ to first order.&lt;/p&gt;

&lt;p&gt;This leads directly to the &lt;strong&gt;Euler-Lagrange equations&lt;/strong&gt;, which describe the systemâ€™s motion.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Let $q(t)$ be the generalized coordinate of the system.&lt;/p&gt;

&lt;p&gt;Action is given by:&lt;/p&gt;

\[S[q(t)] = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt\]

&lt;p&gt;Consider a small variation: $q(t) \rightarrow q(t) + \varepsilon \eta(t)$, where $\eta(t_1) = \eta(t_2) = 0$.&lt;/p&gt;

&lt;p&gt;Then,&lt;/p&gt;

\[\delta S = \int_{t_1}^{t_2} \left( \frac{\partial L}{\partial q} \eta + \frac{\partial L}{\partial \dot{q}} \dot{\eta} \right) dt\]

&lt;p&gt;Integrating by parts the second term:&lt;/p&gt;

\[\delta S = \int_{t_1}^{t_2} \left( \frac{\partial L}{\partial q} - \frac{d}{dt} \frac{\partial L}{\partial \dot{q}} \right) \eta(t) \, dt\]

&lt;p&gt;Since $\eta(t)$ is arbitrary, for $\delta S = 0$:&lt;/p&gt;

\[\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}} \right) - \frac{\partial L}{\partial q} = 0\]

&lt;p&gt;This is the &lt;strong&gt;Euler-Lagrange equation&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Derive the equation of motion for a free particle using the principle of least action.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
The Lagrangian is $L = \frac{1}{2} m \dot{x}^2$.&lt;br /&gt;
Action:&lt;br /&gt;
\(S[x(t)] = \int_{t_1}^{t_2} \frac{1}{2} m \dot{x}^2 \, dt\)
Applying the Euler-Lagrange equation:&lt;br /&gt;
\(\frac{d}{dt}(m \dot{x}) = 0 \Rightarrow \ddot{x} = 0\)
This corresponds to uniform motion.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Use the principle of least action to derive the motion of a harmonic oscillator.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
The Lagrangian is $L = \frac{1}{2} m \dot{x}^2 - \frac{1}{2} k x^2$.&lt;br /&gt;
Euler-Lagrange equation:&lt;br /&gt;
\(\frac{d}{dt}(m \dot{x}) + k x = 0 \Rightarrow m \ddot{x} + k x = 0\)
This is the equation for simple harmonic motion.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The principle of least action is a variational principle for deriving the equations of motion.&lt;/li&gt;
  &lt;li&gt;It unifies many physical laws under a single formalism.&lt;/li&gt;
  &lt;li&gt;The action is stationary, not necessarily minimal.&lt;/li&gt;
  &lt;li&gt;Leads to Euler-Lagrange equations which generalize Newtonâ€™s second law.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Short Answer&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Define the principle of least action.&lt;/li&gt;
      &lt;li&gt;What is meant by stationary action?&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Find the equation of motion for a particle in a linear potential $V(x) = Fx$ using least action.&lt;/li&gt;
      &lt;li&gt;Compute the action for a particle moving at constant speed $v$ from $x=0$ to $x=L$ in time $T$.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MCQs&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Which of the following is minimized in the principle of least action?
        &lt;ul&gt;
          &lt;li&gt;a) Kinetic energy&lt;/li&gt;
          &lt;li&gt;b) Potential energy&lt;/li&gt;
          &lt;li&gt;c) Action&lt;/li&gt;
          &lt;li&gt;d) Hamiltonian&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: c)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The Euler-Lagrange equation is obtained from:
        &lt;ul&gt;
          &lt;li&gt;a) Newtonâ€™s laws&lt;/li&gt;
          &lt;li&gt;b) Hamiltonâ€™s equations&lt;/li&gt;
          &lt;li&gt;c) Principle of least action&lt;/li&gt;
          &lt;li&gt;d) Gaussâ€™s law&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: c)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">The Principle of Least Action</summary></entry><entry><title type="html">Calculus of variation</title><link href="http://localhost:4000/SKMU/lecture/2025/05/19/Calculus-Variation.html" rel="alternate" type="text/html" title="Calculus of variation" /><published>2025-05-19T09:47:26+05:30</published><updated>2025-05-19T09:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/19/Calculus-Variation</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/19/Calculus-Variation.html">&lt;h1 id=&quot;calculus-of-variation&quot;&gt;Calculus of variation&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:darkred&quot;&gt;Learning Objectives&lt;/span&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the foundational concepts of the calculus of variations.&lt;/li&gt;
  &lt;li&gt;Learn techniques to find functions that extremize a given functional.&lt;/li&gt;
  &lt;li&gt;Apply the Euler-Lagrange equation to physical problems such as the brachistochrone, geodesics, and the principle of least action.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Functional&lt;/strong&gt;: A quantity that depends on a function and possibly its derivatives, typically expressed as an integral.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variation ($\delta y$)&lt;/strong&gt;: A small arbitrary change in the function $y(x)$ used to probe how the functional changes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Euler-Lagrange Equation&lt;/strong&gt;: A differential equation derived from the condition that a functional is stationary (has an extremum).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:
The &lt;strong&gt;calculus of variations&lt;/strong&gt; deals with finding functions that make a given functional attain a stationary value (usually a minimum or maximum). A typical problem is to find a function $y(x)$ that extremizes the integral:&lt;/p&gt;

\[I[y] = \int_{x_1}^{x_2} f(x, y, y&apos;) \, dx\]

&lt;p&gt;The basic technique involves:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Introducing a small variation: $y(x) \rightarrow y(x) + \epsilon \eta(x)$, where $\eta(x)$ is an arbitrary smooth function with $\eta(x_1) = \eta(x_2) = 0$.&lt;/li&gt;
  &lt;li&gt;Calculating the first-order change in $I[y]$ with respect to $\epsilon$.&lt;/li&gt;
  &lt;li&gt;Setting $\delta I = 0$ for all $\eta(x)$ leads to the &lt;strong&gt;Euler-Lagrange equation&lt;/strong&gt;:&lt;/li&gt;
&lt;/ol&gt;

\[\frac{\partial f}{\partial y} - \frac{d}{dx} \left( \frac{\partial f}{\partial y&apos;} \right) = 0\]

&lt;p&gt;This equation provides the necessary condition for the function $y(x)$ to make $I[y]$ stationary.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Principle of Least Action in mechanics.&lt;/li&gt;
  &lt;li&gt;Geodesics on surfaces.&lt;/li&gt;
  &lt;li&gt;Brachistochrone problem in dynamics.&lt;/li&gt;
  &lt;li&gt;Optics: Fermatâ€™s principle of least time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:
Consider a functional:&lt;/p&gt;

\[I[y] = \int_{x_1}^{x_2} f(x, y, y&apos;) \, dx\]

&lt;p&gt;To find $y(x)$ such that $I[y]$ is extremized, apply the Euler-Lagrange equation:&lt;/p&gt;

\[\frac{\partial f}{\partial y} - \frac{d}{dx} \left( \frac{\partial f}{\partial y&apos;} \right) = 0\]

&lt;p&gt;&lt;strong&gt;Special Cases&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;If $f$ does not explicitly depend on $y$:&lt;br /&gt;
\(\frac{d}{dx} \left( \frac{\partial f}{\partial y&apos;} \right) = 0\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If $f$ does not explicitly depend on $x$ (Beltrami identity):&lt;br /&gt;
\(f - y&apos; \frac{\partial f}{\partial y&apos;} = \text{constant}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Find the curve $y(x)$ between two points that minimizes the integral&lt;br /&gt;
\(I[y] = \int_{x_1}^{x_2} y&apos;^2 \, dx\)&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
Here, $f = yâ€™^2$, so&lt;br /&gt;
\(\frac{\partial f}{\partial y} = 0, \quad \frac{\partial f}{\partial y&apos;} = 2y&apos;\)&lt;br /&gt;
Then:&lt;br /&gt;
\(\frac{d}{dx}(2y&apos;) = 0 \Rightarrow y&apos;&apos; = 0\)&lt;br /&gt;
Solving:&lt;br /&gt;
\(y(x) = Ax + B\)&lt;br /&gt;
which is a straight line â€” the shortest path between two points.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Use the calculus of variations to find the curve of quickest descent (brachistochrone problem).&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
The time of descent is given by:&lt;br /&gt;
\(T[y] = \int_{x_1}^{x_2} \sqrt{\frac{1 + y&apos;^2}{2gy}} \, dx\)&lt;br /&gt;
Applying the Euler-Lagrange equation leads to a complex differential equation whose solution is a &lt;strong&gt;cycloid&lt;/strong&gt; â€” the curve traced by a point on the rim of a rolling circle.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The Euler-Lagrange equation gives the condition for a function to extremize a functional.&lt;/li&gt;
  &lt;li&gt;Constraints can be handled using the method of Lagrange multipliers.&lt;/li&gt;
  &lt;li&gt;Applications span classical mechanics, optics, and geometry.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Short Answer:
    &lt;ol&gt;
      &lt;li&gt;What is a functional? Give an example.&lt;/li&gt;
      &lt;li&gt;State the Euler-Lagrange equation and explain its significance.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Numerical:
    &lt;ol&gt;
      &lt;li&gt;Find the function $y(x)$ that minimizes $\int_0^1 (yâ€™)^2 \, dx$ with boundary conditions $y(0)=0$, $y(1)=1$.&lt;/li&gt;
      &lt;li&gt;Solve the Euler-Lagrange equation for $f = y^2 + (yâ€™)^2$.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;MCQs:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;The Euler-Lagrange equation is derived from the condition:&lt;br /&gt;
a) $\delta I = \text{maximum}$&lt;br /&gt;
b) $\delta I = \text{minimum}$&lt;br /&gt;
c) $\delta I = 0$&lt;br /&gt;
d) $\delta I = \infty$&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Which of the following is &lt;strong&gt;not&lt;/strong&gt; an application of calculus of variations?&lt;br /&gt;
a) Geodesics&lt;br /&gt;
b) Snellâ€™s law&lt;br /&gt;
c) Newtonâ€™s second law&lt;br /&gt;
d) Principle of least action&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;applications-of-the-calculus-of-variations&quot;&gt;Applications of the Calculus of Variations&lt;/h2&gt;

&lt;p&gt;The calculus of variations plays a crucial role in many physical and geometric problems where a functional (usually representing energy, time, or length) must be minimized or maximized. Below are four fundamental applications:&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;1-principle-of-least-action-in-mechanics&quot;&gt;1. Principle of Least Action in Mechanics&lt;/h3&gt;

&lt;h4 id=&quot;statement&quot;&gt;Statement&lt;/h4&gt;

&lt;p&gt;In classical mechanics, the motion of a particle is such that it minimizes (or makes stationary) the &lt;strong&gt;action functional&lt;/strong&gt;:&lt;/p&gt;

\[S[q(t)] = \int_{t_1}^{t_2} L(q, \dot{q}, t) \, dt\]

&lt;p&gt;Here, $ L = T - V $ is the &lt;strong&gt;Lagrangian&lt;/strong&gt;, where $ T $ is the kinetic energy and $ V $ is the potential energy. The function $ q(t) $ describes the generalized coordinates of the system.&lt;/p&gt;

&lt;h4 id=&quot;eulerlagrange-equation&quot;&gt;Eulerâ€“Lagrange Equation&lt;/h4&gt;

&lt;p&gt;The extremum of the action occurs when:&lt;/p&gt;

\[\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}} \right) - \frac{\partial L}{\partial q} = 0\]

&lt;p&gt;This is known as the &lt;strong&gt;Eulerâ€“Lagrange equation&lt;/strong&gt;, and it leads to &lt;strong&gt;Newtonâ€™s laws&lt;/strong&gt; when applied in the appropriate context.&lt;/p&gt;

&lt;h4 id=&quot;significance&quot;&gt;Significance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Provides a powerful reformulation of classical mechanics.&lt;/li&gt;
  &lt;li&gt;Fundamental in quantum mechanics, field theory, and general relativity.&lt;/li&gt;
  &lt;li&gt;Basis of the Lagrangian and Hamiltonian formalisms.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;2-geodesics-on-surfaces&quot;&gt;2. Geodesics on Surfaces&lt;/h3&gt;

&lt;h4 id=&quot;statement-1&quot;&gt;Statement&lt;/h4&gt;

&lt;p&gt;A &lt;strong&gt;geodesic&lt;/strong&gt; is the shortest path between two points on a curved surface. For example, great circles are geodesics on a sphere.&lt;/p&gt;

&lt;h4 id=&quot;problem&quot;&gt;Problem&lt;/h4&gt;

&lt;p&gt;Given a surface described (parametrically or by a constraint), find the curve $ \gamma(t) = (x(t), y(t), z(t)) $ that minimizes the &lt;strong&gt;arc length&lt;/strong&gt;:&lt;/p&gt;

\[S[\gamma] = \int_a^b \sqrt{\dot{x}^2 + \dot{y}^2 + \dot{z}^2} \, dt\]

&lt;p&gt;Or, in a curved coordinate system with metric $ g_{ij} $:&lt;/p&gt;

\[S[\gamma] = \int_a^b \sqrt{g_{ij} \frac{dx^i}{dt} \frac{dx^j}{dt}} \, dt\]

&lt;h4 id=&quot;example-sphere&quot;&gt;Example: Sphere&lt;/h4&gt;

&lt;p&gt;On a sphere of radius $ R $, the metric is:&lt;/p&gt;

\[ds^2 = R^2(d\theta^2 + \sin^2 \theta\, d\phi^2)\]

&lt;p&gt;Minimizing the arc length leads to the equation of &lt;strong&gt;great circles&lt;/strong&gt;.&lt;/p&gt;

&lt;h4 id=&quot;applications&quot;&gt;Applications&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;General relativity: particles follow geodesics in spacetime.&lt;/li&gt;
  &lt;li&gt;Navigation: shortest paths on Earth.&lt;/li&gt;
  &lt;li&gt;Computer graphics and robotics.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;3-brachistochrone-problem-in-dynamics&quot;&gt;3. Brachistochrone Problem in Dynamics&lt;/h3&gt;

&lt;h4 id=&quot;statement-2&quot;&gt;Statement&lt;/h4&gt;

&lt;p&gt;Find the curve between two points (not vertically aligned) along which a particle slides under gravity in the &lt;strong&gt;least time&lt;/strong&gt;, assuming no friction.&lt;/p&gt;

&lt;h4 id=&quot;functional-to-minimize&quot;&gt;Functional to Minimize&lt;/h4&gt;

\[T[y] = \int_{x_1}^{x_2} \sqrt{\frac{1 + (y&apos;)^2}{2gy}} \, dx\]

&lt;p&gt;Using the calculus of variations and the &lt;strong&gt;Beltrami identity&lt;/strong&gt;, one derives the curve of fastest descent.&lt;/p&gt;

&lt;h4 id=&quot;solution&quot;&gt;Solution&lt;/h4&gt;

&lt;p&gt;The solution is a &lt;strong&gt;cycloid&lt;/strong&gt;, given parametrically as:&lt;/p&gt;

\[x = a(\theta - \sin \theta), \quad y = a(1 - \cos \theta)\]

&lt;h4 id=&quot;significance-1&quot;&gt;Significance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Originated the field of variational calculus (posed by Johann Bernoulli in 1696).&lt;/li&gt;
  &lt;li&gt;Early example where minimizing time (not distance or energy) leads to a surprising result.&lt;/li&gt;
  &lt;li&gt;Important in physics and engineering for time-optimization problems.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;4-optics-fermats-principle-of-least-time&quot;&gt;4. Optics: Fermatâ€™s Principle of Least Time&lt;/h3&gt;

&lt;h4 id=&quot;statement-3&quot;&gt;Statement&lt;/h4&gt;

&lt;p&gt;Fermatâ€™s principle states that light takes the path which &lt;strong&gt;minimizes the time&lt;/strong&gt; taken to travel between two points.&lt;/p&gt;

&lt;h4 id=&quot;mathematical-formulation&quot;&gt;Mathematical Formulation&lt;/h4&gt;

&lt;p&gt;If the speed of light varies with position, say $ v(x) = \frac{1}{n(x)} $, where $ n(x) $ is the refractive index, then the &lt;strong&gt;time&lt;/strong&gt; taken is:&lt;/p&gt;

\[T[y] = \int_{x_1}^{x_2} \frac{\sqrt{1 + (y&apos;)^2}}{v(x, y)} \, dx\]

&lt;p&gt;This is a variational problem where the &lt;strong&gt;path of light&lt;/strong&gt; $ y(x) $ extremizes the travel time.&lt;/p&gt;

&lt;h4 id=&quot;example-snells-law&quot;&gt;Example: Snellâ€™s Law&lt;/h4&gt;

&lt;p&gt;Applying the calculus of variations to two media with different refractive indices leads to:&lt;/p&gt;

\[\frac{\sin \theta_1}{v_1} = \frac{\sin \theta_2}{v_2}\]

&lt;p&gt;This is &lt;strong&gt;Snellâ€™s law&lt;/strong&gt; of refraction.&lt;/p&gt;

&lt;h4 id=&quot;significance-2&quot;&gt;Significance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Foundation of geometrical optics.&lt;/li&gt;
  &lt;li&gt;Connects variational principles to physical phenomena.&lt;/li&gt;
  &lt;li&gt;Analogous to least action in mechanics and leads to ray-tracing methods.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-IV" /><summary type="html">Calculus of variation</summary></entry><entry><title type="html">Lagrangeâ€™s Equation</title><link href="http://localhost:4000/SKMU/lecture/2025/05/18/Lagrange-Equation.html" rel="alternate" type="text/html" title="Lagrangeâ€™s Equation" /><published>2025-05-18T07:47:26+05:30</published><updated>2025-05-18T07:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/18/Lagrange-Equation</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/18/Lagrange-Equation.html">&lt;h2 id=&quot;dalemberts-principle-lagranges-equation-and-its-simple-applications&quot;&gt;Dâ€™Alembertâ€™s Principle, Lagrangeâ€™s Equation and Its Simple Applications&lt;/h2&gt;

&lt;h4 id=&quot;1-dalemberts-principle&quot;&gt;1. Dâ€™Alembertâ€™s Principle&lt;/h4&gt;

&lt;p&gt;Dâ€™Alembertâ€™s principle is a fundamental concept in classical mechanics that provides an alternative formulation of Newtonâ€™s second law by incorporating the concept of virtual work. It states that the sum of the differences between the applied forces and the inertial forces (also called the generalized forces) acting on a system in equilibrium is zero when projected along any virtual displacement.&lt;/p&gt;

&lt;h5 id=&quot;11-mathematical-formulation&quot;&gt;1.1 Mathematical Formulation&lt;/h5&gt;

&lt;p&gt;Consider a system of \(N\) particles, where each particle has mass \(m_i\), position vector \(\mathbf{r}_i\), and is subject to an external force \(\mathbf{F}_i\). Newtonâ€™s second law states:&lt;/p&gt;

\[m_i \ddot{\mathbf{r}}_i = \mathbf{F}_i\]

&lt;p&gt;Dâ€™Alembertâ€™s principle introduces the concept of &lt;strong&gt;inertial force&lt;/strong&gt;:&lt;/p&gt;

\[\mathbf{F}_i - m_i \ddot{\mathbf{r}}_i = 0\]

&lt;p&gt;For an infinitesimal virtual displacement \(\delta \mathbf{r}_i\), the principle states:&lt;/p&gt;

\[\sum_{i=1}^{N} (\mathbf{F}_i - m_i \ddot{\mathbf{r}}_i) \cdot \delta \mathbf{r}_i = 0\]

&lt;p&gt;Since the constraint forces do no virtual work (ideal constraints), we are left with only generalized forces:&lt;/p&gt;

\[\sum_{i=1}^{N} (\mathbf{F}_i^{(a)} - m_i \ddot{\mathbf{r}}_i) \cdot \delta \mathbf{r}_i = 0\]

&lt;p&gt;where \(\mathbf{F}_i^{(a)}\) represents the applied forces excluding constraint forces.&lt;/p&gt;

&lt;h4 id=&quot;2-lagranges-equation&quot;&gt;2. Lagrangeâ€™s Equation&lt;/h4&gt;

&lt;p&gt;Lagrangeâ€™s equation is derived using Dâ€™Alembertâ€™s principle and is particularly useful in dealing with systems having constraints.&lt;/p&gt;

&lt;h5 id=&quot;21-generalized-coordinates&quot;&gt;2.1 Generalized Coordinates&lt;/h5&gt;

&lt;p&gt;A system with \(N\) particles and \(k\) constraint equations can be described using a reduced set of &lt;strong&gt;generalized coordinates&lt;/strong&gt;:&lt;/p&gt;

\[q_1, q_2, \dots, q_n, \quad n = 3N - k\]

&lt;p&gt;The relationship between Cartesian coordinates and generalized coordinates is given by:&lt;/p&gt;

\[\mathbf{r}_i = \mathbf{r}_i(q_1, q_2, ..., q_n, t)\]

&lt;p&gt;The virtual displacement then transforms as:&lt;/p&gt;

\[\delta \mathbf{r}_i = \sum_{j=1}^{n} \frac{\partial \mathbf{r}_i}{\partial q_j} \delta q_j\]

&lt;p&gt;Using these transformations, Dâ€™Alembertâ€™s principle can be rewritten in terms of generalized coordinates.&lt;/p&gt;

&lt;h5 id=&quot;22-derivation-of-lagranges-equation&quot;&gt;2.2 Derivation of Lagrangeâ€™s Equation&lt;/h5&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;a href=&quot;/SKMU/assets/pdf/Lagrange.pdf&quot; target=&quot;_blank&quot;&gt;
    &lt;button style=&quot;padding: 6px 12px; background-color: #007BFF; color: white; border: none; border-radius: 4px; cursor: pointer;&quot;&gt;
      ðŸ“„ Click here for derivation
    &lt;/button&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;3-simple-applications-of-lagranges-equations&quot;&gt;3. Simple Applications of Lagrangeâ€™s Equations&lt;/h4&gt;

&lt;h5 id=&quot;31-simple-pendulum&quot;&gt;3.1 Simple Pendulum&lt;/h5&gt;

&lt;p&gt;A simple pendulum consists of a mass \(m\) attached to a string of length \(l\). The generalized coordinate is the angular displacement \(\theta\).&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/SKMU/assets/images/Lecture/pendulum.png&quot; alt=&quot;Scattering&quot; class=&quot;my-custom-class&quot; style=&quot;width:40%; height:auto;&quot; /&gt;
&lt;/div&gt;

&lt;h5 id=&quot;-coordinates&quot;&gt;ðŸ”¹ Coordinates&lt;/h5&gt;
&lt;p&gt;Use angle \(\theta\) as generalized coordinate.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Position: \(x = \ell \sin \theta, \quad y = -\ell \cos \theta\)&lt;/li&gt;
  &lt;li&gt;Velocity: \(v^2 = \ell^2 \dot{\theta}^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-energy&quot;&gt;ðŸ”¹ Energy&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Kinetic Energy:
\(T = \frac{1}{2} m (l^2 \dot{\theta}^2)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Potential Energy:
\(V = -mgl \cos \theta\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;-lagrangian&quot;&gt;ðŸ”¹ Lagrangian&lt;/h5&gt;

\[L = T - V = \frac{1}{2} m \ell^2 \dot{\theta}^2 - m g \ell (1 - \cos \theta)\]

&lt;p&gt;Apply Lagrangeâ€™s equation:&lt;/p&gt;

\[\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{\theta}} \right) 
- \frac{\partial L}{\partial \theta} = 0\]

\[\Rightarrow \frac{d}{dt} (m \ell^2 \dot{\theta}) + m g \ell \sin \theta = 0
\Rightarrow \boxed{ \ddot{\theta} + \frac{g}{\ell} \sin \theta = 0 }\]

&lt;h5 id=&quot;32-bead-on-a-rotating-hoop&quot;&gt;3.2 Bead on a Rotating Hoop&lt;/h5&gt;

&lt;p&gt;A bead of mass \(m\) moves on a hoop of radius \(R\) that rotates with a constant angular velocity \(\omega\).&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/SKMU/assets/images/Lecture/rotating-hoop.png&quot; alt=&quot;Scattering&quot; class=&quot;my-custom-class&quot; style=&quot;width:40%; height:auto;&quot; /&gt;
&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Generalized coordinate: \(\theta\) (angle of displacement on the hoop)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kinetic Energy:
\(T = \frac{1}{2} m (R^2 \dot{\theta}^2 + \omega^2 R^2 \sin^2 \theta)\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Potential Energy:
\(V = -mgR \cos \theta\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Lagrangian:
\(L = \frac{1}{2} m (R^2 \dot{\theta}^2 + \omega^2 R^2 \sin^2 \theta) + mgR \cos \theta\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Applying Lagrangeâ€™s equation:&lt;/p&gt;

\[\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{\theta}} \right) - \frac{\partial L}{\partial \theta} = 0\]

\[mR^2 \ddot{\theta} - m R^2 \omega^2 \sin \theta \cos \theta + mgR \sin \theta = 0\]

&lt;p&gt;which governs the motion of the bead on the rotating hoop.&lt;/p&gt;

&lt;!-- ---
---
# Hamiltonâ€™s Principle and Calculus of Variations


---
---

## ðŸ“˜ 1. Introduction to Hamiltonâ€™s Principle

Hamiltonâ€™s principle is a reformulation of classical mechanics that provides a powerful and elegant approach to deriving the equations of motion. It is also known as the **principle of stationary action**.

#### ðŸ”¹ Statement of Hamiltonâ€™s Principle

&gt; The actual path taken by a physical system between two configurations at fixed times $$ t_1 $$ and $$ t_2 $$ is such that the **action integral** is **stationary** (usually a minimum).

Mathematically,
$$
\delta S = 0, \quad \text{where} \quad S = \int_{t_1}^{t_2} L(q_i, \dot{q}_i, t) \, dt
$$
- $$ L $$ is the Lagrangian: $$ L = T - V $$
- $$ S $$ is called the **action**
- $$ \delta S = 0 $$ implies a stationary value (not necessarily minimum)


## ðŸ“˜ 2. Techniques of the Calculus of Variations

The calculus of variations deals with finding functions that make a **functional** stationary.

#### ðŸ”¹ 2.1 Functional Form

A functional is an integral of the form:
$$
J[y] = \int_{x_1}^{x_2} f(y, y&apos;, x)\, dx
$$
The goal is to find the function $$ y(x) $$ such that $$ J[y] $$ is stationary.

#### ðŸ”¹ 2.2 Euler-Lagrange Equation (Core Result)

If $$ y(x) $$ gives an extremum to $$ J[y] $$, then it must satisfy:
$$
\frac{d}{dx} \left( \frac{\partial f}{\partial y&apos;} \right) - \frac{\partial f}{\partial y} = 0
$$

---

#### ðŸ§  Example 1: Shortest Path Between Two Points

Letâ€™s find the shortest path between two points $$ A(x_1, y_1) $$ and $$ B(x_2, y_2) $$.

&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/SKMU/assets/images/Lecture/brachistrone.png&quot; 
       alt=&quot;Scattering&quot; 
       class=&quot;my-custom-class&quot; 
       style=&quot;width:40%; height:auto;&quot;&gt;
&lt;/div&gt;

**Functional:**
$$
J[y] = \int_{x_1}^{x_2} \sqrt{1 + (y&apos;)^2} \, dx
$$

Apply Euler-Lagrange:

Let $$ f = \sqrt{1 + (y&apos;)^2} $$, then:
$$
\frac{\partial f}{\partial y} = 0,\quad \frac{\partial f}{\partial y&apos;} = \frac{y&apos;}{\sqrt{1 + (y&apos;)^2}}
$$

Now,
$$
\frac{d}{dx} \left( \frac{y&apos;}{\sqrt{1 + (y&apos;)^2}} \right) = 0
\Rightarrow \frac{y&apos;}{\sqrt{1 + (y&apos;)^2}} = C
\Rightarrow y&apos; = \text{constant} \Rightarrow y = mx + c
$$

âœ… The result is a straight line â€” confirming that the shortest path is a straight line.

---

## ðŸ“˜ 3. Deriving Lagrange&apos;s Equation Using Hamilton&apos;s Principle

#### ðŸ”¹ 3.1 Setup

Let the system have $$ n $$ generalized coordinates $$ q_1, q_2, ..., q_n $$. The Lagrangian is $$ L(q_i, \dot{q}_i, t) $$.

The action is:
$$
S = \int_{t_1}^{t_2} L(q_i, \dot{q}_i, t) \, dt
$$

We vary the path $$ q_i(t) \to q_i(t) + \delta q_i(t) $$ with fixed endpoints:
$$
\delta q_i(t_1) = \delta q_i(t_2) = 0
$$

We compute the variation:
$$
\delta S = \int_{t_1}^{t_2} \left( \sum_i \frac{\partial L}{\partial q_i} \delta q_i + \frac{\partial L}{\partial \dot{q}_i} \delta \dot{q}_i \right) dt
$$

Using $$ \delta \dot{q}_i = \frac{d}{dt}(\delta q_i) $$, and integration by parts:

$$
\int_{t_1}^{t_2} \frac{\partial L}{\partial \dot{q}_i} \frac{d}{dt}(\delta q_i) \, dt = 
\left. \frac{\partial L}{\partial \dot{q}_i} \delta q_i \right|_{t_1}^{t_2} 
- \int_{t_1}^{t_2} \frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}_i} \right) \delta q_i \, dt
$$

Since $$ \delta q_i(t_1) = \delta q_i(t_2) = 0 $$, the boundary term vanishes.

Thus:
$$
\delta S = \int_{t_1}^{t_2} \sum_i \left( \frac{\partial L}{\partial q_i} - \frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}_i} \right) \right) \delta q_i \, dt
$$

Since $$ \delta q_i $$ are arbitrary, for $$ \delta S = 0 $$, the integrand must vanish:

#### âœ… Final Result: **Lagrangeâ€™s Equations**
$$
\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}_i} \right) - \frac{\partial L}{\partial q_i} = 0, \quad i = 1, 2, \dots, n
$$

---
---
# Conservation Theorems, Symmetry, Hamiltonâ€™s Equations, and Least Action Principle

---
---

## ðŸ“˜ 1. Conservation Theorems and Symmetry Properties

In Lagrangian and Hamiltonian mechanics, **symmetries** of a system lead to corresponding **conservation laws**.

This deep connection is formally stated in **Noetherâ€™s theorem**.


#### ðŸ”¹ 1.1 Noetherâ€™s Theorem (Statement)

&gt; If the Lagrangian is invariant under a continuous transformation, there exists a corresponding conserved quantity.

#### ðŸ”¹ 1.2 Common Symmetries and Conservation Laws

| Symmetry Type              | Conserved Quantity        |
|----------------------------|---------------------------|
| Time translation invariance| Energy                    |
| Spatial translation        | Linear momentum           |
| Rotational invariance      | Angular momentum          |

#### ðŸ§  Example: Particle in Central Force Field

Let a particle move under a central potential $$ V(r) $$.

- Lagrangian: $$ L = \frac{1}{2} m (\dot{r}^2 + r^2 \dot{\theta}^2) - V(r) $$
- $$ \theta $$ is cyclic: $$ \partial L / \partial \theta = 0 $$
- â‡’ Angular momentum $$ p_\theta = \frac{\partial L}{\partial \dot{\theta}} = m r^2 \dot{\theta} $$ is **conserved**


## ðŸ“˜ 2. Hamiltonâ€™s Equations of Motion

Hamiltonian formulation is an alternative to Lagrangian mechanics and is especially useful in advanced physics.



#### ðŸ”¹ 2.1 Definition of the Hamiltonian

For a system with Lagrangian $$ L(q_i, \dot{q}_i, t) $$, define the **generalized momenta**:
$$
p_i = \frac{\partial L}{\partial \dot{q}_i}
$$

Then the **Hamiltonian** is:
$$
H(q_i, p_i, t) = \sum_i p_i \dot{q}_i - L
$$


#### ðŸ”¹ 2.2 Hamilton&apos;s Canonical Equations

From the total differential $$ dH $$, we get:

$$
\boxed{
\begin{aligned}
\dot{q}_i &amp;= \frac{\partial H}{\partial p_i} \\
\dot{p}_i &amp;= -\frac{\partial H}{\partial q_i}
\end{aligned}
}
$$

These are **Hamiltonâ€™s equations of motion**.


#### ðŸ§  Example: Simple Harmonic Oscillator

Lagrangian:
$$
L = \frac{1}{2} m \dot{x}^2 - \frac{1}{2} k x^2
$$

Generalized momentum:
$$
p = \frac{\partial L}{\partial \dot{x}} = m \dot{x}
\Rightarrow \dot{x} = \frac{p}{m}
$$

Hamiltonian:
$$
H = p \dot{x} - L = \frac{p^2}{2m} + \frac{1}{2} k x^2
$$

Hamiltonâ€™s equations:
$$
\dot{x} = \frac{\partial H}{\partial p} = \frac{p}{m}, \quad
\dot{p} = -\frac{\partial H}{\partial x} = -k x
$$

â‡’ Same equations as from Newtonâ€™s second law.



## ðŸ“˜ 3. Principle of Least Action

#### ðŸ”¹ 3.1 What is Action?

Action is defined as:
$$
S = \int_{t_1}^{t_2} L(q_i, \dot{q}_i, t) \, dt
$$

#### ðŸ”¹ 3.2 Principle of Least Action

&gt; The path taken by the system between two points in configuration space is the one that **minimizes** (or makes stationary) the action $$ S $$.

This principle is equivalent to Hamiltonâ€™s principle:
$$
\delta S = 0
$$

It leads directly to the **Euler-Lagrange equations**, i.e., **Lagrangeâ€™s equations**:
$$
\frac{d}{dt} \left( \frac{\partial L}{\partial \dot{q}_i} \right) - \frac{\partial L}{\partial q_i} = 0
$$


## ðŸ§  Example: Free Particle in One Dimension

- Lagrangian: $$ L = \frac{1}{2} m \dot{x}^2 $$
- Action: $$ S = \int_{t_1}^{t_2} \frac{1}{2} m \dot{x}^2 \, dt $$

Using the calculus of variations, the path that minimizes $$ S $$ satisfies:
$$
\frac{d}{dt} \left( m \dot{x} \right) = 0 \Rightarrow \ddot{x} = 0
\Rightarrow x(t) = At + B
$$

âœ… The path is a straight line â€” consistent with Newtonâ€™s first law.


## ðŸ“˜ 4. Take Home Message

| Concept                    | Key Idea                                                        |
|---------------------------|------------------------------------------------------------------|
| Noether&apos;s Theorem         | Symmetries â‡’ Conservation laws                                   |
| Hamilton&apos;s Equations      | 1st-order equations in $$ q_i, p_i $$; derived from Hamiltonian  |
| Principle of Least Action | System follows path that makes action stationary                |

---

#### ðŸ” Difference between Hamiltonâ€™s Principle and Principle of Least Action

| Aspect                        | Hamiltonâ€™s Principle                                       | Principle of Least Action                              |
|------------------------------|------------------------------------------------------------|--------------------------------------------------------|
| ðŸ”¹ Definition                | States that the action integral is **stationary** (Î´S = 0) | States that action is **minimized** (least possible S) |
| ðŸ”¹ Type of extremum         | Can be **minimum, maximum, or saddle point**              | Specifically implies a **minimum**                    |
| ðŸ”¹ Generality                | More general â€“ applies even when action is not minimum     | Special case of Hamiltonâ€™s principle                  |
| ðŸ”¹ Mathematical Formulation | $$ \delta S = 0 $$                                         | $$ S = \min \int L \, dt $$                            |
| ðŸ”¹ Physical Use             | Used to derive Lagrangeâ€™s equations                        | Used primarily in heuristic arguments                 |

âœ… **Note**: In most practical physical systems, the action is **minimized**, so the two are often used interchangeably. However, **Hamiltonâ€™s principle is more general**.

---
---

# Hamiltonâ€“Jacobi Equation

---

## ðŸ”¹ 1. Introduction to Hamiltonâ€“Jacobi Theory

Hamiltonâ€“Jacobi theory provides a powerful **analytical method** for solving mechanical problems. It reformulates classical mechanics into a **first-order partial differential equation (PDE)**.


## ðŸ”¹ 2. The Hamiltonâ€“Jacobi Equation

Given a Hamiltonian $$ H(q_i, p_i, t) $$, the **Hamiltonâ€“Jacobi equation (HJE)** is:

$$
\boxed{
H \left(q_i, \frac{\partial S}{\partial q_i}, t \right) + \frac{\partial S}{\partial t} = 0
}
$$

Here, $$ S(q_i, \alpha_i, t) $$ is called **Hamiltonâ€™s principal function**, and $$ \alpha_i $$ are constants of integration.

For time-independent Hamiltonians, we use **Hamiltonâ€™s characteristic function** $$ W(q_i, \alpha_i) $$:

$$
\boxed{
H \left(q_i, \frac{\partial W}{\partial q_i} \right) = E
}
$$


## ðŸ”¹ 3. Why Use HJE?

- Converts the problem of solving $$ 2n $$ ODEs to solving **one PDE**.
- Particularly useful for systems with **cyclic coordinates**.
- A bridge to **quantum mechanics** (via SchrÃ¶dinger equation).


## ðŸ§  4. Example: 1D Harmonic Oscillator

**Given:**
Mass $$ m $$, spring constant $$ k $$, natural frequency $$ \omega = \sqrt{k/m} $$

**Hamiltonian**:
$$
H = \frac{p^2}{2m} + \frac{1}{2} k q^2
$$


#### ðŸ”¹ Step 1: Setup the Hamiltonâ€“Jacobi Equation

Let $$ S(q, t) $$ be Hamilton&apos;s principal function.

The HJE becomes:
$$
\frac{1}{2m} \left( \frac{\partial S}{\partial q} \right)^2 + \frac{1}{2} k q^2 + \frac{\partial S}{\partial t} = 0
$$


#### ðŸ”¹ Step 2: Separation of Variables

Assume:
$$
S(q, t) = W(q) - Et
$$

Substitute into HJE:
$$
\frac{1}{2m} \left( \frac{dW}{dq} \right)^2 + \frac{1}{2} k q^2 = E
$$


#### ðŸ”¹ Step 3: Solve for $$ W(q) $$

$$
\left( \frac{dW}{dq} \right)^2 = 2m \left(E - \frac{1}{2} k q^2 \right)
\Rightarrow
\frac{dW}{dq} = \sqrt{2m \left(E - \frac{1}{2} k q^2 \right)}
$$

Integrating:
$$
W(q) = \int \sqrt{2m \left(E - \frac{1}{2} k q^2 \right)} \, dq
$$

This is a **standard integral**:
$$
W(q) = \frac{m \omega}{2} \left( q \sqrt{A^2 - q^2} + A^2 \sin^{-1}\left( \frac{q}{A} \right) \right), \quad \text{where } A = \sqrt{\frac{2E}{k}}
$$


#### ðŸ”¹ Step 4: Use Action-Angle Variables

Define the **action**:
$$
J = \oint p \, dq = \oint \sqrt{2m \left(E - \frac{1}{2} k q^2 \right)} \, dq = 2\pi \frac{E}{\omega}
\Rightarrow E = \omega J
$$

This leads to **quantization** in old quantum theory and gives the energy in terms of the action variable.





---
---
# ðŸ“˜ Canonical Transformations and Poisson Brackets

---

## ðŸ”¹ 1. Canonical Transformations

A **canonical transformation** is a change of phase space coordinates:
$$
(q_i, p_i) \rightarrow (Q_i, P_i)
$$
that preserves the **form of Hamiltonâ€™s equations**.

#### ðŸ”¸ Motivation:
Canonical transformations simplify problems by preserving the structure of Hamiltonâ€™s mechanics, particularly the **symplectic structure**.

&gt; **symplectic structure**: ensures that **Hamiltonâ€™s equations remain invariant under canonical transformations** and that the **phase space volume is conserved** over time (Liouvilleâ€™s theorem).  
&gt;
&gt; In short, the symplectic structure guarantees that Hamiltonian dynamics are **area-preserving, reversible**, and fully determined by the geometry of phase space.



#### ðŸ”¸ Condition:
The transformation is canonical if:

$$
\sum_i p_i \, dq_i - H \, dt = \sum_i P_i \, dQ_i - K \, dt + dF
$$

where $$ F $$ is a **generating function** and $$ K $$ is the new Hamiltonian.



## ðŸ”¹ 2. Generating Functions

Canonical transformations can be generated using a **generating function** $$ F $$, which can be expressed in four common types:

| Type | Generating Function | Transformation Relations |
|------|---------------------|---------------------------|
| $$ F_1(q, Q, t) $$ | $$ F_1 $$ | $$ p = \partial F_1 / \partial q $$, $$ P = -\partial F_1 / \partial Q $$ |
| $$ F_2(q, P, t) $$ | $$ F_2 $$ | $$ p = \partial F_2 / \partial q $$, $$ Q = \partial F_2 / \partial P $$ |
| $$ F_3(p, Q, t) $$ | $$ F_3 $$ | $$ q = -\partial F_3 / \partial p $$, $$ P = -\partial F_3 / \partial Q $$ |
| $$ F_4(p, P, t) $$ | $$ F_4 $$ | $$ q = -\partial F_4 / \partial p $$, $$ Q = \partial F_4 / \partial P $$ |

âœ… These functions allow us to generate transformations that maintain canonical structure.


## ðŸ”¹ 3. Infinitesimal Canonical Transformations

An **infinitesimal canonical transformation** is a small transformation parameterized by $$ \epsilon $$:

$$
Q_i = q_i + \epsilon \frac{\partial G}{\partial p_i}, \quad
P_i = p_i - \epsilon \frac{\partial G}{\partial q_i}
$$

where $$ G(q, p) $$ is the **generator** of the transformation.

These generators are crucial in understanding **symmetries** and **conserved quantities** (via Noetherâ€™s theorem).



## ðŸ”¹ 4. Poisson Brackets

The **Poisson bracket** between two functions $$ f(q, p, t) $$ and $$ g(q, p, t) $$ is defined as:

$$
\{f, g\} = \sum_i \left( \frac{\partial f}{\partial q_i} \frac{\partial g}{\partial p_i} - \frac{\partial f}{\partial p_i} \frac{\partial g}{\partial q_i} \right)
$$

### ðŸ”¸ Properties:

1. **Antisymmetry**: $$ \{f, g\} = -\{g, f\} $$
2. **Linearity**: $$ \{af + bg, h\} = a\{f, h\} + b\{g, h\} $$
3. **Leibniz Rule**: $$ \{fg, h\} = f\{g, h\} + g\{f, h\} $$
4. **Jacobi Identity**: $$ \{f, \{g, h\}\} + \{g, \{h, f\}\} + \{h, \{f, g\}\} = 0 $$



## ðŸ”¹ 5. Fundamental Poisson Brackets

$$
\{q_i, q_j\} = 0, \quad \{p_i, p_j\} = 0, \quad \{q_i, p_j\} = \delta_{ij}
$$

These relations mirror the canonical commutation relations in quantum mechanics.



## ðŸ”¹ 6. Poissonâ€™s Theorems

Let $$ f(q, p, t) $$ and $$ g(q, p, t) $$ be any two functions in phase space:

#### ðŸ”¸ Theorem 1: Time Evolution
$$
\frac{df}{dt} = \{f, H\} + \frac{\partial f}{\partial t}
$$

This is the classical version of **Heisenberg&apos;s equation of motion**.

#### ðŸ”¸ Theorem 2: Invariance under Canonical Transformation
Poisson brackets are **invariant under canonical transformations**:
$$
\{f, g\}_{(q, p)} = \{f, g\}_{(Q, P)}
$$

This invariance confirms that canonical transformations preserve physical laws.



## ðŸ§  Example: Angular Momentum Components

For a particle in 3D space, angular momentum $$ \vec{L} = \vec{r} \times \vec{p} $$. The components obey:

$$
\{L_x, L_y\} = L_z, \quad \{L_y, L_z\} = L_x, \quad \{L_z, L_x\} = L_y
$$

This shows that angular momentum components generate **rotational transformations**.




## ðŸ“Ž References

- H. Goldstein, *Classical Mechanics*, 3rd Edition  
- L.D. Landau &amp; E.M. Lifshitz, *Mechanics*  
- V.I. Arnold, *Mathematical Methods of Classical Mechanics*

--- --&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">Dâ€™Alembertâ€™s Principle, Lagrangeâ€™s Equation and Its Simple Applications</summary></entry><entry><title type="html">Dielectric Properties of Materials</title><link href="http://localhost:4000/SKMU/lecture/2025/05/16/Dielectrics.html" rel="alternate" type="text/html" title="Dielectric Properties of Materials" /><published>2025-05-16T09:47:26+05:30</published><updated>2025-05-16T09:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/05/16/Dielectrics</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/05/16/Dielectrics.html">&lt;h1 id=&quot;macroscopic-dielectric-constant&quot;&gt;Macroscopic Dielectric Constant&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Learning Objectives&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the concept of macroscopic dielectric constant in materials.&lt;/li&gt;
  &lt;li&gt;Explore the relationship between electric field, polarization, and dielectric behavior.&lt;/li&gt;
  &lt;li&gt;Apply the concept to calculate fields, capacitance, and material properties.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Dielectric Constant ($\varepsilon_r$)&lt;/strong&gt;: The ratio of the permittivity of a material to the permittivity of free space. It measures the materialâ€™s ability to reduce the electric field:
\(\varepsilon_r = \frac{\varepsilon}{\varepsilon_0}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Polarization ($\vec{P}$)&lt;/strong&gt;: The dipole moment per unit volume of a dielectric, induced by an external electric field.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Electric Susceptibility ($\chi_e$)&lt;/strong&gt;: A dimensionless quantity that describes how easily a material can be polarized:
\(\vec{P} = \varepsilon_0 \chi_e \vec{E}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$E$ (Macroscopic Electric Field)&lt;/strong&gt;: The average electric field in the dielectric material due to both external sources and the materialâ€™s polarization.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$E_{\text{ext}}$ (External Field)&lt;/strong&gt;: The electric field applied from outside the dielectric, typically produced by free charges (e.g., on capacitor plates), before considering the dielectric response.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$E_{\text{pol}}$ (Polarization Field)&lt;/strong&gt;: The electric field arising from the polarized bound charges within the dielectric material; it generally opposes the external field.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;$E_{\text{local}}$ (Local Field)&lt;/strong&gt;: The actual microscopic electric field experienced by an individual molecule or atom, including contributions from both the external field and nearby polarized molecules.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;When an external electric field is applied to a dielectric material, the bound charges within atoms or molecules slightly displace, creating induced dipoles. The collective effect of these dipoles leads to a net polarization $\vec{P}$ in the material.&lt;/p&gt;

&lt;p&gt;This polarization generates an internal electric field that partially cancels the applied field, resulting in a reduced &lt;strong&gt;macroscopic electric field&lt;/strong&gt; $\vec{E}$ inside the material.&lt;/p&gt;

&lt;p&gt;To describe the behavior of a dielectric, we define the &lt;strong&gt;electric displacement field&lt;/strong&gt; $\vec{D}$:
\(\vec{D} = \varepsilon_0 \vec{E} + \vec{P}\)&lt;/p&gt;

&lt;p&gt;In linear, isotropic, and homogeneous dielectrics, polarization is directly proportional to the electric field:
\(\vec{P} = \varepsilon_0 \chi_e \vec{E}\)&lt;/p&gt;

&lt;p&gt;Substituting this into the equation for $\vec{D}$ gives:
\(\vec{D} = \varepsilon_0 (1 + \chi_e) \vec{E} = \varepsilon \vec{E}\)&lt;/p&gt;

&lt;p&gt;Thus, the &lt;strong&gt;permittivity&lt;/strong&gt; of the dielectric is:
\(\varepsilon = \varepsilon_0 (1 + \chi_e)\)&lt;/p&gt;

&lt;p&gt;And the &lt;strong&gt;dielectric constant&lt;/strong&gt; (relative permittivity) is:
\(\varepsilon_r = \frac{\varepsilon}{\varepsilon_0} = 1 + \chi_e\)&lt;/p&gt;

&lt;p&gt;This quantity indicates how much the presence of the dielectric reduces the internal electric field compared to vacuum.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Electric displacement field:
\(\vec{D} = \varepsilon_0 \vec{E} + \vec{P}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Polarization in linear media:
\(\vec{P} = \varepsilon_0 \chi_e \vec{E}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Displacement field in terms of dielectric constant:
\(\vec{D} = \varepsilon \vec{E}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Dielectric constant:
\(\varepsilon_r = \frac{\varepsilon}{\varepsilon_0} = 1 + \chi_e\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Capacitance with dielectric:
\(C = \varepsilon_r \cdot C_0 = \varepsilon_r \cdot \frac{\varepsilon_0 A}{d}\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;$C_0$ = Capacitance in vacuum&lt;/li&gt;
  &lt;li&gt;$A$ = Area of capacitor plates&lt;/li&gt;
  &lt;li&gt;$d$ = Distance between plates&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: A parallel-plate capacitor has vacuum between the plates and a capacitance of 10 pF. What will be its capacitance if a dielectric with dielectric constant $\varepsilon_r = 4$ is inserted?&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
\(C = \varepsilon_r \cdot C_0 = 4 \cdot 10 = 40 \, \text{pF}\)&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: 40 pF&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: A dielectric has a polarization $\vec{P} = 2 \times 10^{-7} \, \text{C/m}^2$ and is subjected to an electric field $E = 500 \, \text{V/m}$. Find its dielectric constant.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
\(\chi_e = \frac{P}{\varepsilon_0 E} = \frac{2 \times 10^{-7}}{8.85 \times 10^{-12} \times 500} \approx 45.2\)
\(\varepsilon_r = 1 + \chi_e = 1 + 45.2 = 46.2\)&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: $\varepsilon_r \approx 46.2$&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The dielectric constant describes the materialâ€™s ability to reduce an internal electric field.&lt;/li&gt;
  &lt;li&gt;It is dimensionless and always greater than or equal to 1.&lt;/li&gt;
  &lt;li&gt;A higher $\varepsilon_r$ implies better electric insulation and greater capacitance.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Short Answer&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;Define the macroscopic dielectric constant and explain how it differs from permittivity.&lt;/li&gt;
      &lt;li&gt;What is the physical meaning of electric susceptibility?&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;A dielectric has $\chi_e = 2.5$. Calculate its dielectric constant.&lt;/li&gt;
      &lt;li&gt;A capacitor has plate area $0.01 \, \text{m}^2$ and plate separation $2 \, \text{mm}$. Calculate its capacitance with $\varepsilon_r = 3$.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MCQs&lt;/strong&gt;:
    &lt;ol&gt;
      &lt;li&gt;The dielectric constant $\varepsilon_r$ is:
        &lt;ul&gt;
          &lt;li&gt;(a) less than 1&lt;/li&gt;
          &lt;li&gt;(b) equal to 1&lt;/li&gt;
          &lt;li&gt;(c) always greater than 1&lt;/li&gt;
          &lt;li&gt;(d) can be negative&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: (c)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;The correct relation between $\vec{D}$, $\vec{E}$, and $\vec{P}$ is:
        &lt;ul&gt;
          &lt;li&gt;(a) $\vec{D} = \vec{E} + \vec{P}$&lt;/li&gt;
          &lt;li&gt;(b) $\vec{D} = \varepsilon_0 \vec{E} + \vec{P}$&lt;/li&gt;
          &lt;li&gt;(c) $\vec{D} = \varepsilon_r \vec{P}$&lt;/li&gt;
          &lt;li&gt;(d) $\vec{D} = \vec{P} - \varepsilon \vec{E}$&lt;br /&gt;
&lt;strong&gt;Answer&lt;/strong&gt;: (b)&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;The &lt;strong&gt;mechanisms of polarization&lt;/strong&gt; include:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Electronic Polarization&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Occurs in all dielectric materials.&lt;/li&gt;
      &lt;li&gt;Caused by the displacement of the electron cloud relative to the nucleus in atoms.&lt;/li&gt;
      &lt;li&gt;Dominant at high frequencies (e.g., optical range).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ionic Polarization&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Present in ionic crystals (e.g., NaCl).&lt;/li&gt;
      &lt;li&gt;Results from the relative displacement of positive and negative ions.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Orientation Polarization&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Occurs in materials with permanent dipole moments.&lt;/li&gt;
      &lt;li&gt;Dipoles align with the external electric field.&lt;/li&gt;
      &lt;li&gt;Temperature-dependent and significant at lower frequencies.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Space Charge Polarization&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Arises from charge accumulation at interfaces or grain boundaries.&lt;/li&gt;
      &lt;li&gt;Prominent at low frequencies.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: A dielectric with electric susceptibility $\chi_e = 2.5$ is placed in an electric field of magnitude $E = 10^5$ V/m. Find the polarization vector $\vec{P}$.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
Using $\vec{P} = \epsilon_0 \chi_e \vec{E}$:&lt;br /&gt;
\(\vec{P} = (8.85 \times 10^{-12} \, \text{F/m})(2.5)(10^5 \, \text{V/m}) = 2.21 \times 10^{-6} \, \text{C/m}^2\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Determine the electric displacement $\vec{D}$ for a dielectric with $\epsilon_0 = 8.85 \times 10^{-12}$ F/m, $\chi_e = 3$, and $E = 2 \times 10^4$ V/m.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
First calculate $\vec{P}$:&lt;br /&gt;
\(\vec{P} = \epsilon_0 \chi_e \vec{E} = (8.85 \times 10^{-12})(3)(2 \times 10^4) = 5.31 \times 10^{-7} \, \text{C/m}^2\)&lt;br /&gt;
Then,&lt;br /&gt;
\(\vec{D} = \epsilon_0 \vec{E} + \vec{P} = (8.85 \times 10^{-12})(2 \times 10^4) + 5.31 \times 10^{-7} = 7.08 \times 10^{-7} \, \text{C/m}^2\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Short Answer:
    &lt;ol&gt;
      &lt;li&gt;What is electronic polarization?&lt;/li&gt;
      &lt;li&gt;How does temperature affect orientation polarization?&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Numerical:
    &lt;ol&gt;
      &lt;li&gt;A dielectric with $\chi_e = 4$ is placed in a field of $E = 3 \times 10^5$ V/m. Calculate $\vec{P}$.&lt;/li&gt;
      &lt;li&gt;Given $\vec{E} = 10^4$ V/m and $\vec{P} = 1.77 \times 10^{-6}$ C/mÂ², find $\vec{D}$.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;MCQs:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;Which type of polarization is dominant in the optical frequency range?&lt;br /&gt;
a) Ionic&lt;br /&gt;
b) Electronic&lt;br /&gt;
c) Orientation&lt;br /&gt;
d) Space charge&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The unit of polarization vector $\vec{P}$ is:&lt;br /&gt;
a) V/m&lt;br /&gt;
b) C/mÂ²&lt;br /&gt;
c) F/m&lt;br /&gt;
d) N/C&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;clausius-mossotti-equation&quot;&gt;Clausius-Mossotti Equation&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:darkred&quot;&gt;Learning Objectives&lt;/span&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand the relationship between microscopic polarizability and macroscopic dielectric constant.&lt;/li&gt;
  &lt;li&gt;Derive the Clausius-Mossotti equation.&lt;/li&gt;
  &lt;li&gt;Apply the equation to determine the polarizability of molecules in a dielectric.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Polarizability ($\alpha$)&lt;/strong&gt;: The measure of how easily an electron cloud of a molecule is distorted by an external electric field.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Number Density ($N$)&lt;/strong&gt;: Number of molecules per unit volume in the dielectric material.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Theory and Explanation&lt;/strong&gt;:
The &lt;strong&gt;Clausius-Mossotti equation&lt;/strong&gt; connects the &lt;strong&gt;microscopic property&lt;/strong&gt; of molecules (polarizability $\alpha$) with the &lt;strong&gt;macroscopic property&lt;/strong&gt; of the dielectric (relative permittivity $\epsilon_r$).&lt;/p&gt;

&lt;p&gt;When an external electric field is applied, the molecules of the dielectric become polarized. The total polarization $\vec{P}$ depends on the polarizability $\alpha$ and the number of molecules per unit volume $N$.&lt;/p&gt;

\[\vec{P} = N \vec{p} = N \alpha \vec{E}_{\text{local}}\]

&lt;p&gt;However, the field experienced by a molecule is &lt;strong&gt;not&lt;/strong&gt; simply the applied field. It is modified due to the field created by other polarized molecules. This &lt;strong&gt;local field&lt;/strong&gt; is often approximated using the &lt;strong&gt;Lorentz model&lt;/strong&gt;, assuming the molecule is inside a spherical cavity within a uniformly polarized medium.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step-by-Step Derivation&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Macroscopic Polarization&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;From basic electromagnetism, polarization in a linear dielectric is given by:&lt;/p&gt;

\[\vec{P} = \epsilon_0 \chi_e \vec{E}\]

    &lt;p&gt;where $\vec{E}$ is the &lt;strong&gt;macroscopic field&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Microscopic Polarization&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;For an individual molecule with polarizability $\alpha$, the &lt;strong&gt;induced dipole moment&lt;/strong&gt; is:&lt;/p&gt;

\[\vec{p} = \alpha \vec{E}_{\text{local}}\]

    &lt;p&gt;Therefore, polarization becomes:&lt;/p&gt;

\[\vec{P} = N \vec{p} = N \alpha \vec{E}_{\text{local}}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Local Field Estimation&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;The &lt;strong&gt;local electric field&lt;/strong&gt; is the sum of the macroscopic electric field \(\vec{E}\) and the field due to surrounding polarized molecules $\vec{E}_{\text{pol}}$.&lt;/p&gt;

    &lt;p&gt;Using Lorentzâ€™s method, the field at the center of a uniformly polarized spherical cavity is:&lt;/p&gt;

\[\vec{E}_{\text{pol}} = \frac{\vec{P}}{3 \epsilon_0}\]

    &lt;p&gt;Hence, the &lt;strong&gt;local field&lt;/strong&gt; becomes:&lt;/p&gt;

\[\vec{E}_{\text{local}} = \vec{E}+ \frac{\vec{P}}{3 \epsilon_0}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Substituting into Microscopic Expression&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;Substituting $\vec{E}_{\text{local}}$ into the microscopic equation:&lt;/p&gt;

\[\vec{P} = N \alpha \left( \vec{E} + \frac{\vec{P}}{3 \epsilon_0} \right)\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Solving for $\vec{P}$&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;Expand and isolate $\vec{P}$:&lt;/p&gt;

\[\vec{P} = N \alpha \vec{E} + \frac{N \alpha}{3 \epsilon_0} \vec{P}\]

    &lt;p&gt;Rearranged:&lt;/p&gt;

\[\vec{P} \left(1 - \frac{N \alpha}{3 \epsilon_0} \right) = N \alpha \vec{E}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Expressing $\vec{P}$&lt;/strong&gt;:&lt;/p&gt;

\[\vec{P} = \frac{N \alpha}{1 - \frac{N \alpha}{3 \epsilon_0}} \vec{E}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Relating to Macroscopic Susceptibility&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;Since $\vec{P} = \epsilon_0 \chi_e \vec{E}$,&lt;/p&gt;

\[\epsilon_0 \chi_e = \frac{N \alpha}{1 - \frac{N \alpha}{3 \epsilon_0}}\]

    &lt;p&gt;Multiply both sides by the denominator:&lt;/p&gt;

\[\epsilon_0 \chi_e \left(1 - \frac{N \alpha}{3 \epsilon_0}\right) = N \alpha\]

    &lt;p&gt;Expand:&lt;/p&gt;

\[\epsilon_0 \chi_e - \frac{N \alpha \chi_e}{3} = N \alpha\]

    &lt;p&gt;Bring all terms to one side:&lt;/p&gt;

\[\epsilon_0 \chi_e = N \alpha \left(1 + \frac{\chi_e}{3} \right)\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Solving for $\alpha$&lt;/strong&gt;:&lt;/p&gt;

\[\alpha = \frac{3 \epsilon_0}{N} \cdot \frac{\chi_e}{3 + \chi_e}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;In Terms of Relative Permittivity $\epsilon_r = 1 + \chi_e$&lt;/strong&gt;:&lt;/p&gt;

    &lt;p&gt;Replace $\chi_e = \epsilon_r - 1$:&lt;/p&gt;

\[\alpha = \frac{3 \epsilon_0}{N} \cdot \frac{\epsilon_r - 1}{\epsilon_r + 2}\]

    &lt;p&gt;This is the &lt;strong&gt;Clausius-Mossotti Equation&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:
The Clausius-Mossotti equation is:&lt;/p&gt;

\[\frac{\epsilon_r - 1}{\epsilon_r + 2} = \frac{N \alpha}{3 \epsilon_0}\]

\[\alpha = \frac{3 \epsilon_0}{N} \cdot \frac{\epsilon_r - 1}{\epsilon_r + 2}\]

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: A gas has a relative permittivity $\epsilon_r = 1.0006$ and molecular density $N = 2.5 \times 10^{25}$ molecules/mÂ³. Find the polarizability $\alpha$.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
Using:
\(\alpha = \frac{3 \epsilon_0}{N} \cdot \frac{\epsilon_r - 1}{\epsilon_r + 2}\)&lt;br /&gt;
\(\alpha = \frac{3 \times 8.85 \times 10^{-12}}{2.5 \times 10^{25}} \cdot \frac{0.0006}{1.0006 + 2}\)&lt;br /&gt;
\(\alpha \approx \frac{2.655 \times 10^{-11}}{2.5 \times 10^{25}} \cdot \frac{0.0006}{3.0006}\)&lt;br /&gt;
\(\alpha \approx 2.12 \times 10^{-40} \, \text{FÂ·m}^2\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Determine the relative permittivity $\epsilon_r$ of a dielectric with polarizability $\alpha = 1 \times 10^{-39}$ FÂ·mÂ² and number density $N = 5 \times 10^{28}$ mâ»Â³.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
Using:
\(\frac{\epsilon_r - 1}{\epsilon_r + 2} = \frac{N \alpha}{3 \epsilon_0}\)&lt;br /&gt;
Calculate RHS:
\(\frac{(5 \times 10^{28}) (1 \times 10^{-39})}{3 \times 8.85 \times 10^{-12}} = \frac{5 \times 10^{-11}}{2.655 \times 10^{-11}} \approx 1.884\)&lt;br /&gt;
So,
\(\frac{\epsilon_r - 1}{\epsilon_r + 2} = 1.884\)&lt;br /&gt;
Solve for $\epsilon_r$:
\((\epsilon_r - 1) = 1.884 (\epsilon_r + 2)\)&lt;br /&gt;
\(\epsilon_r - 1 = 1.884 \epsilon_r + 3.768\)&lt;br /&gt;
\(-0.884 \epsilon_r = 4.768 \Rightarrow \epsilon_r \approx -5.39\)&lt;br /&gt;
(Negative value indicates inconsistencyâ€”check units or values used; realistic $\epsilon_r$ should be &amp;gt; 1)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The Clausius-Mossotti equation links microscopic and macroscopic dielectric behavior.&lt;/li&gt;
  &lt;li&gt;Valid primarily for dilute gases and non-polar materials.&lt;/li&gt;
  &lt;li&gt;Fails when interactions between molecules are strong or in polar materials at high density.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Short Answer:
    &lt;ol&gt;
      &lt;li&gt;What does the Clausius-Mossotti equation represent physically?&lt;/li&gt;
      &lt;li&gt;List the assumptions made in deriving the Clausius-Mossotti relation.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Numerical:
    &lt;ol&gt;
      &lt;li&gt;Calculate $\alpha$ for a dielectric with $\epsilon_r = 1.0008$ and $N = 1.5 \times 10^{25}$ mâ»Â³.&lt;/li&gt;
      &lt;li&gt;Given $\alpha = 2 \times 10^{-40}$ FÂ·mÂ² and $N = 2 \times 10^{26}$ mâ»Â³, find $\epsilon_r$.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;MCQs:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;The Clausius-Mossotti equation is applicable when:&lt;br /&gt;
a) Material is metallic&lt;br /&gt;
b) Intermolecular interactions are strong&lt;br /&gt;
c) The medium is dilute and non-polar&lt;br /&gt;
d) The dielectric is ferroelectric&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;In the Clausius-Mossotti equation, the term $\alpha$ represents:&lt;br /&gt;
a) Dielectric constant&lt;br /&gt;
b) Electric susceptibility&lt;br /&gt;
c) Molecular polarizability&lt;br /&gt;
d) Local field intensity&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;frequency-dependence-of-polarizabilities-dielectric-constant-in-alternating-fields-and-clausius-mossotti-catastrophe&quot;&gt;Frequency Dependence of Polarizabilities, Dielectric Constant in Alternating Fields, and Clausius-Mossotti Catastrophe&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color:darkred&quot;&gt;Learning Objectives&lt;/span&gt;&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understand how various types of polarizabilities respond to different frequency ranges and timescales.&lt;/li&gt;
  &lt;li&gt;Analyze the behavior of dielectric constant as a function of frequency, and interpret complex dielectric response.&lt;/li&gt;
  &lt;li&gt;Explore the Clausius-Mossotti relation and the physical significance of the conditions leading to the catastrophe.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key Concepts / Definitions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Clausius-Mossotti Catastrophe&lt;/strong&gt;: A theoretical prediction from the Clausius-Mossotti equation where the dielectric constant becomes infinite if $N\alpha \to 3\epsilon_0$, signaling a breakdown of linear dielectric behavior or phase transition.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;frequency-dependence&quot;&gt;&lt;strong&gt;Frequency Dependence&lt;/strong&gt;:&lt;/h3&gt;

&lt;p&gt;As the &lt;strong&gt;frequency&lt;/strong&gt; of the applied alternating electric field increases, different polarization mechanisms in a dielectric respond differently depending on their intrinsic time scales. These mechanisms include:&lt;/p&gt;

&lt;h4 id=&quot;a-electronic-polarizability&quot;&gt;&lt;strong&gt;(a) Electronic Polarizability&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Origin&lt;/strong&gt;: Displacement of the electron cloud relative to the nucleus in an atom or molecule.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Response Time&lt;/strong&gt;: Very fast (~$10^{-15}$ s).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Active Range&lt;/strong&gt;: Remains active up to &lt;strong&gt;optical and ultraviolet frequencies&lt;/strong&gt; (~$10^{15}$ Hz).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remarks&lt;/strong&gt;: Since electrons are light and bound by strong restoring forces, they can respond to very high-frequency fields.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;b-ionic-polarizability&quot;&gt;&lt;strong&gt;(b) Ionic Polarizability&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Origin&lt;/strong&gt;: Displacement of positive and negative ions relative to each other in ionic crystals.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Response Time&lt;/strong&gt;: Moderate (~$10^{-13}$ to $10^{-14}$ s).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Active Range&lt;/strong&gt;: Prominent in the &lt;strong&gt;infrared&lt;/strong&gt; frequency range (~$10^{13}$ Hz).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remarks&lt;/strong&gt;: Ionic motion becomes too slow to respond at higher frequencies due to inertia.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;c-dipolar-orientation-polarizability&quot;&gt;&lt;strong&gt;(c) Dipolar (Orientation) Polarizability&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Origin&lt;/strong&gt;: Alignment of permanent dipole moments in molecules (e.g., H$_2$O, HCl) with the external field.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Response Time&lt;/strong&gt;: Slow (~$10^{-9}$ to $10^{-12}$ s).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Active Range&lt;/strong&gt;: Effective at &lt;strong&gt;microwave and radio&lt;/strong&gt; frequencies (~$10^9$ Hz).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remarks&lt;/strong&gt;: Thermal agitation and molecular rotation limit the ability of dipoles to reorient at high frequency.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;d-space-charge-interfacial-polarizability&quot;&gt;&lt;strong&gt;(d) Space Charge (Interfacial) Polarizability&lt;/strong&gt;&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Origin&lt;/strong&gt;: Accumulation of charges at interfaces or grain boundaries in heterogeneous materials.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Response Time&lt;/strong&gt;: Very slow (milliseconds or longer).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Active Range&lt;/strong&gt;: Significant only at &lt;strong&gt;very low frequencies&lt;/strong&gt; (below ~$10^3$ Hz).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remarks&lt;/strong&gt;: These charges cannot follow rapid field reversals due to low mobility.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As frequency increases:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;At &lt;strong&gt;low frequencies&lt;/strong&gt;: all polarization mechanisms contribute, so $\epsilon_r$ is large.&lt;/li&gt;
  &lt;li&gt;At &lt;strong&gt;intermediate frequencies&lt;/strong&gt;: dipolar and space charge mechanisms cannot respond quickly, their contribution vanishes.&lt;/li&gt;
  &lt;li&gt;At &lt;strong&gt;high frequencies&lt;/strong&gt;: only &lt;strong&gt;electronic&lt;/strong&gt; (and sometimes &lt;strong&gt;ionic&lt;/strong&gt;) polarizability remains.&lt;/li&gt;
  &lt;li&gt;At &lt;strong&gt;optical frequencies&lt;/strong&gt;: dielectric constant reduces to $\epsilon_\infty$, corresponding to pure electronic polarization.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This results in a &lt;strong&gt;stepwise decrease&lt;/strong&gt; in dielectric constant with increasing frequency, known as &lt;strong&gt;dielectric dispersion&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;dielectric-loss-and-complex-permittivity&quot;&gt;&lt;strong&gt;Dielectric Loss and Complex Permittivity&lt;/strong&gt;:&lt;/h3&gt;

&lt;p&gt;In alternating fields, some energy is dissipated due to lag in polarization response. The dielectric constant becomes a complex quantity:&lt;/p&gt;

\[\epsilon(\omega) = \epsilon&apos;(\omega) - i \epsilon&apos;&apos;(\omega)\]

&lt;ul&gt;
  &lt;li&gt;$\epsilonâ€™(\omega)$: stores energy (capacitive behavior).&lt;/li&gt;
  &lt;li&gt;$\epsilonâ€™â€™(\omega)$: represents energy loss (resistive behavior), also known as &lt;strong&gt;dielectric loss&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The &lt;strong&gt;loss tangent&lt;/strong&gt; or &lt;strong&gt;dissipation factor&lt;/strong&gt; is defined as:&lt;/p&gt;

\[\tan \delta = \frac{\epsilon&apos;&apos;}{\epsilon&apos;}\]

&lt;!-- ---

### **Debye Relaxation Model**:

For polar dielectrics, the **Debye model** explains frequency dependence of $\epsilon(\omega)$:

$$
\epsilon(\omega) = \epsilon_\infty + \frac{\epsilon_s - \epsilon_\infty}{1 + i \omega \tau}
$$

Where:
- $\epsilon_s$ is the **static dielectric constant** (low-frequency limit),
- $\epsilon_\infty$ is the **high-frequency limit** (purely electronic),
- $\tau$ is the **relaxation time** (characteristic response time).

At $\omega \tau = 1$, dielectric loss $\epsilon&apos;&apos;(\omega)$ is **maximum**.

--- --&gt;

&lt;h3 id=&quot;clausius-mossotti-relation-and-catastrophe&quot;&gt;&lt;strong&gt;Clausius-Mossotti Relation and Catastrophe&lt;/strong&gt;:&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Clausius-Mossotti equation&lt;/strong&gt; connects microscopic polarizability $\alpha$ with macroscopic dielectric constant $\epsilon_r$:&lt;/p&gt;

\[\frac{\epsilon_r - 1}{\epsilon_r + 2} = \frac{N \alpha}{3 \epsilon_0}\]

&lt;p&gt;Rewriting:&lt;/p&gt;

\[\epsilon_r = \frac{1 + 2\left(\frac{N \alpha}{3 \epsilon_0}\right)}{1 - \left(\frac{N \alpha}{3 \epsilon_0}\right)}\]

&lt;p&gt;This shows that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;As $N \alpha \to 3 \epsilon_0$, $\epsilon_r \to \infty$&lt;/li&gt;
  &lt;li&gt;This is the &lt;strong&gt;Clausius-Mossotti Catastrophe&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;This condition implies that polarization grows uncontrollably.&lt;/li&gt;
  &lt;li&gt;Indicates a phase transition, such as the onset of &lt;strong&gt;ferroelectricity&lt;/strong&gt; or dielectric breakdown.&lt;/li&gt;
  &lt;li&gt;Physically, the system can no longer support a linear dielectric response.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Mathematical Formulation&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Complex dielectric function&lt;/strong&gt;:
\(\epsilon(\omega) = \epsilon&apos;(\omega) - i \epsilon&apos;&apos;(\omega)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- - **Debye model**:
  $$
  \epsilon(\omega) = \epsilon_\infty + \frac{\epsilon_s - \epsilon_\infty}{1 + i \omega \tau}
  $$ --&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Clausius-Mossotti relation&lt;/strong&gt;:
\(\frac{\epsilon_r - 1}{\epsilon_r + 2} = \frac{N \alpha}{3 \epsilon_0}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Solved Examples&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 1&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: A dielectric has $\epsilon_s = 10$, $\epsilon_\infty = 2$, and $\tau = 10^{-6}$ s. Find $\epsilon(\omega)$ at $f = 10^6$ Hz.&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
\(\omega = 2 \pi f = 2 \pi \times 10^6 \, \text{rad/s}\)&lt;br /&gt;
\(\epsilon(\omega) = 2 + \frac{8}{1 + i (2\pi)}\)&lt;br /&gt;
Rationalize the denominator:&lt;br /&gt;
\(\epsilon(\omega) = 2 + \frac{8(1 - i 2\pi)}{1 + (2\pi)^2}\)&lt;br /&gt;
Compute numeric real and imaginary parts for final values.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Example 2&lt;/strong&gt;:&lt;br /&gt;
&lt;strong&gt;Problem&lt;/strong&gt;: Determine if Clausius-Mossotti catastrophe occurs for $N = 5 \times 10^{28}$ mâ»Â³, $\alpha = 1.6 \times 10^{-40}$ FÂ·mÂ².&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;:&lt;br /&gt;
\(\frac{N \alpha}{3 \epsilon_0} = \frac{(5 \times 10^{28})(1.6 \times 10^{-40})}{3 \times 8.85 \times 10^{-12}} \approx 0.30\)&lt;br /&gt;
Since the value &amp;lt; 1, &lt;strong&gt;no catastrophe&lt;/strong&gt;. Catastrophe occurs when the ratio â†’ 1.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Important Points / Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Polarizability mechanisms respond over different frequency ranges; the total dielectric constant depends on which are active.&lt;/li&gt;
  &lt;li&gt;In AC fields, dielectric constant becomes complex and shows dispersion and loss.&lt;/li&gt;
  &lt;li&gt;The Clausius-Mossotti catastrophe signals the breakdown of linear dielectric behavior and may indicate phase transitions in materials.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Practice Questions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Short Answer:
    &lt;ol&gt;
      &lt;li&gt;Explain why $\epsilonâ€™â€™(\omega)$ becomes zero at high frequencies.&lt;/li&gt;
      &lt;li&gt;Why does $\epsilon_r$ decrease with increasing frequency?&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Numerical:
    &lt;ol&gt;
      &lt;li&gt;Calculate $\epsilon(\omega)$ for a material with $\epsilon_s = 12$, $\epsilon_\infty = 4$, and $\tau = 5 \times 10^{-7}$ s at $f = 1$ MHz.&lt;/li&gt;
      &lt;li&gt;For a dielectric with $N = 4 \times 10^{28}$ mâ»Â³ and $\alpha = 2 \times 10^{-40}$ FÂ·mÂ², compute $\epsilon_r$ using the Clausius-Mossotti equation.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;MCQs:
    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;At high frequencies (e.g., optical range), which type of polarization dominates?&lt;br /&gt;
a) Dipolar&lt;br /&gt;
b) Ionic&lt;br /&gt;
c) Space charge&lt;br /&gt;
d) Electronic&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;The Clausius-Mossotti relation predicts divergence in $\epsilon_r$ when:&lt;br /&gt;
a) $N \alpha = \epsilon_0$&lt;br /&gt;
b) $N \alpha = 2 \epsilon_0$&lt;br /&gt;
c) $N \alpha = 3 \epsilon_0$&lt;br /&gt;
d) $N \alpha = 0$&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-IV" /><summary type="html">Macroscopic Dielectric Constant</summary></entry><entry><title type="html">Numerical Methods</title><link href="http://localhost:4000/SKMU/lecture/2025/04/28/Numerical-Methods.html" rel="alternate" type="text/html" title="Numerical Methods" /><published>2025-04-28T09:47:26+05:30</published><updated>2025-04-28T09:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/04/28/Numerical-Methods</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/04/28/Numerical-Methods.html">&lt;p&gt;Eigenvalues and eigenvectors play a central role in linear algebra, with wide applications in physics, engineering, and data science. They help understand the action of a linear transformation in a given vector space.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-basic-definitions&quot;&gt;ðŸ”¹ Basic Definitions&lt;/h2&gt;

&lt;p&gt;Let \(A\) be an \(n \times n\) square matrix. A non-zero vector \(\mathbf{v} \in \mathbb{R}^n\) is called an &lt;strong&gt;eigenvector&lt;/strong&gt; of \(A\) if it satisfies:&lt;/p&gt;

\[A \mathbf{v} = \lambda \mathbf{v}\]

&lt;p&gt;Here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\lambda \in \mathbb{R}\) (or \(\mathbb{C}\)) is the &lt;strong&gt;eigenvalue&lt;/strong&gt; corresponding to eigenvector \(\mathbf{v}\).&lt;/li&gt;
  &lt;li&gt;\(\mathbf{v} \ne \mathbf{0}\) is a &lt;strong&gt;direction preserved&lt;/strong&gt; under the transformation by \(A\), scaled by \(\lambda\).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-how-to-find-eigenvalues-and-eigenvectors&quot;&gt;ðŸ”¹ How to Find Eigenvalues and Eigenvectors&lt;/h2&gt;

&lt;h3 id=&quot;step-1-characteristic-equation&quot;&gt;Step 1: Characteristic Equation&lt;/h3&gt;

&lt;p&gt;To find eigenvalues, solve the &lt;strong&gt;characteristic equation&lt;/strong&gt;:&lt;/p&gt;

\[\det(A - \lambda I) = 0\]

&lt;ul&gt;
  &lt;li&gt;\(I\) is the identity matrix of the same size as \(A\).&lt;/li&gt;
  &lt;li&gt;The determinant gives a polynomial in \(\lambda\) called the &lt;strong&gt;characteristic polynomial&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;step-2-solve-for-eigenvectors&quot;&gt;Step 2: Solve for Eigenvectors&lt;/h3&gt;

&lt;p&gt;For each eigenvalue \(\lambda\), solve the system:&lt;/p&gt;

\[(A - \lambda I) \mathbf{v} = 0\]

&lt;p&gt;to find the corresponding eigenvector(s) \(\mathbf{v}\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-example&quot;&gt;ðŸ”¸ Example&lt;/h2&gt;

&lt;p&gt;Let&lt;/p&gt;

\[A = \begin{bmatrix}
2 &amp;amp; 1 \\
1 &amp;amp; 2
\end{bmatrix}\]

&lt;h3 id=&quot;step-1-find-eigenvalues&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

&lt;p&gt;Solve:&lt;/p&gt;

\[\det(A - \lambda I) = \det \begin{bmatrix}
2 - \lambda &amp;amp; 1 \\
1 &amp;amp; 2 - \lambda
\end{bmatrix}
= (2 - \lambda)^2 - 1 = 0\]

&lt;p&gt;So,&lt;/p&gt;

\[(2 - \lambda)^2 = 1 \Rightarrow \lambda = 1, 3\]

&lt;h3 id=&quot;step-2-find-eigenvectors&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;For \(\lambda = 1\):&lt;/p&gt;

\[(A - I) \mathbf{v} = \begin{bmatrix}
1 &amp;amp; 1 \\
1 &amp;amp; 1
\end{bmatrix} \begin{bmatrix}
x \\
y
\end{bmatrix} = 0
\Rightarrow x + y = 0 \Rightarrow \mathbf{v}_1 = \begin{bmatrix} 1 \\ -1 \end{bmatrix}\]

&lt;p&gt;For \(\lambda = 3\):&lt;/p&gt;

\[(A - 3I) \mathbf{v} = \begin{bmatrix}
-1 &amp;amp; 1 \\
1 &amp;amp; -1
\end{bmatrix} \begin{bmatrix}
x \\
y
\end{bmatrix} = 0
\Rightarrow x - y = 0 \Rightarrow \mathbf{v}_2 = \begin{bmatrix} 1 \\ 1 \end{bmatrix}\]

&lt;hr /&gt;

&lt;h2 id=&quot;-key-properties&quot;&gt;ðŸ”¹ Key Properties&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;A matrix of size \(n \times n\) has at most \(n\) eigenvalues.&lt;/li&gt;
  &lt;li&gt;Eigenvectors corresponding to &lt;strong&gt;distinct eigenvalues are linearly independent&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;If a matrix is &lt;strong&gt;symmetric&lt;/strong&gt;, all its eigenvalues are real and eigenvectors are orthogonal.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-physical-interpretation&quot;&gt;ðŸ”¹ Physical Interpretation&lt;/h2&gt;

&lt;p&gt;In physics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;In quantum mechanics, eigenvalues of operators represent &lt;strong&gt;observable quantities&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;In mechanics, the &lt;strong&gt;normal modes&lt;/strong&gt; of oscillation are eigenvectors of the system matrix.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-summary&quot;&gt;ðŸ“Œ Summary&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Term&lt;/th&gt;
      &lt;th&gt;Meaning&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Eigenvalue&lt;/td&gt;
      &lt;td&gt;Scalar \(\lambda\) such that \(A \mathbf{v} = \lambda \mathbf{v}\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Eigenvector&lt;/td&gt;
      &lt;td&gt;Non-zero vector \(\mathbf{v}\) preserved in direction by \(A\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Characteristic Equation&lt;/td&gt;
      &lt;td&gt;\(\det(A - \lambda I) = 0\) to find eigenvalues&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Matrix Diagonalization&lt;/td&gt;
      &lt;td&gt;Possible if matrix has \(n\) linearly independent eigenvectors&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;
&lt;h1 id=&quot;-interpolation-extrapolation-and-curve-fitting&quot;&gt;ðŸ“˜ Interpolation, Extrapolation, and Curve Fitting&lt;/h1&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-1-interpolation&quot;&gt;ðŸ”¹ 1. Interpolation&lt;/h2&gt;

&lt;h3 id=&quot;-definition&quot;&gt;ðŸ”¸ Definition:&lt;/h3&gt;

&lt;p&gt;Interpolation is the process of estimating unknown values that fall &lt;strong&gt;within the range&lt;/strong&gt; of known data points.&lt;/p&gt;

&lt;h3 id=&quot;-types-of-interpolation&quot;&gt;ðŸ”¸ Types of Interpolation:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear Interpolation&lt;/strong&gt;: Straight line between two known points.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Polynomial Interpolation&lt;/strong&gt;: Uses a polynomial of degree $n$ for $n+1$ data points.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Spline Interpolation&lt;/strong&gt;: Piecewise polynomials (e.g., cubic spline) to ensure smoothness.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-formula-linear-interpolation&quot;&gt;ðŸ”¸ Formula (Linear Interpolation):&lt;/h3&gt;

&lt;p&gt;Given two points $(x_0, y_0)$ and $(x_1, y_1)$:&lt;/p&gt;

\[y = y_0 + \frac{(x - x_0)(y_1 - y_0)}{x_1 - x_0}\]

&lt;h3 id=&quot;-example-linear-interpolation&quot;&gt;ðŸ”¸ Example (Linear Interpolation):&lt;/h3&gt;

&lt;p&gt;Let $(x_0, y_0) = (1, 3)$ and $(x_1, y_1) = (4, 15)$. Estimate $y$ at $x = 2$.&lt;/p&gt;

\[y = 3 + \frac{(2 - 1)(15 - 3)}{4 - 1} = 3 + \frac{1 \cdot 12}{3} = 3 + 4 = 7\]

&lt;p&gt;So, the interpolated value at $x = 2$ is $y = 7$.&lt;/p&gt;

&lt;h3 id=&quot;-applications&quot;&gt;ðŸ”¸ Applications:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Filling missing data&lt;/li&gt;
  &lt;li&gt;Digital image scaling&lt;/li&gt;
  &lt;li&gt;Sensor data smoothing&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ï¸-2-extrapolation&quot;&gt;ðŸ—™ï¸ 2. Extrapolation&lt;/h2&gt;

&lt;h3 id=&quot;-definition-1&quot;&gt;ðŸ”¸ Definition:&lt;/h3&gt;

&lt;p&gt;Extrapolation estimates values &lt;strong&gt;outside the range&lt;/strong&gt; of known data points using the trend of the data.&lt;/p&gt;

&lt;h3 id=&quot;-types&quot;&gt;ðŸ”¸ Types:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear Extrapolation&lt;/strong&gt;: Extends the linear trend.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Polynomial Extrapolation&lt;/strong&gt;: Uses higher-order polynomials to forecast.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-risks&quot;&gt;ðŸ”¸ Risks:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Less reliable than interpolation.&lt;/li&gt;
  &lt;li&gt;Assumes the current trend continues.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-example-linear&quot;&gt;ðŸ”¸ Example (Linear):&lt;/h3&gt;

&lt;p&gt;Given last two points: $(x_{n-1}, y_{n-1}) = (2, 5)$ and $(x_n, y_n) = (4, 11)$, estimate $y$ at $x = 5$.&lt;/p&gt;

\[y = 11 + (5 - 4) \cdot \frac{11 - 5}{4 - 2} = 11 + 1 \cdot 3 = 14\]

&lt;p&gt;So, the extrapolated value at $x = 5$ is $y = 14$.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-3-curve-fitting-methods&quot;&gt;ðŸ”¹ 3. Curve Fitting Methods&lt;/h2&gt;

&lt;h3 id=&quot;-definition-2&quot;&gt;ðŸ”¸ Definition:&lt;/h3&gt;

&lt;p&gt;Curve fitting finds a curve that best represents the trend in the data. It can be used to model the relationship between variables.&lt;/p&gt;

&lt;h3 id=&quot;-methods&quot;&gt;ðŸ”¸ Methods:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Polynomial Fit&lt;/strong&gt;: Fit using polynomials (linear, quadratic, cubic, etc.).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Exponential Fit&lt;/strong&gt;: $y = ae^{bx}$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Logarithmic Fit&lt;/strong&gt;: $y = a + b \log x$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Power Law Fit&lt;/strong&gt;: $y = ax^b$&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Piecewise Fit&lt;/strong&gt;: Different models in different intervals.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-example-polynomial-fit&quot;&gt;ðŸ”¸ Example (Polynomial Fit):&lt;/h3&gt;

&lt;p&gt;Given data: $(1, 2)$, $(2, 4.1)$, $(3, 6.2)$&lt;/p&gt;

&lt;p&gt;Fit a line: $y = mx + c$ using least squares:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normal equations lead to $m \approx 2.1$, $c \approx -0.1$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, best-fit line: $y = 2.1x - 0.1$&lt;/p&gt;

&lt;h3 id=&quot;-purpose&quot;&gt;ðŸ”¸ Purpose:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Data modeling&lt;/li&gt;
  &lt;li&gt;Predictive analytics&lt;/li&gt;
  &lt;li&gt;Simplification of complex datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-tools&quot;&gt;ðŸ”¸ Tools:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Manual fitting&lt;/li&gt;
  &lt;li&gt;Python libraries: NumPy (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;polyfit&lt;/code&gt;), SciPy, Matplotlib&lt;/li&gt;
  &lt;li&gt;MATLAB, Excel&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-4-least-squares-fitting&quot;&gt;ðŸ”¹ 4. Least Squares Fitting&lt;/h2&gt;

&lt;h3 id=&quot;-definition-3&quot;&gt;ðŸ”¸ Definition:&lt;/h3&gt;

&lt;p&gt;The least squares method minimizes the &lt;strong&gt;sum of the squares of the vertical differences&lt;/strong&gt; (residuals) between the observed and predicted values.&lt;/p&gt;

&lt;h3 id=&quot;-linear-least-squares&quot;&gt;ðŸ”¸ Linear Least Squares:&lt;/h3&gt;

&lt;p&gt;Given data points $(x_i, y_i)$, find $y = mx + c$ that minimizes:&lt;/p&gt;

\[S = \sum_{i=1}^n (y_i - (mx_i + c))^2\]

&lt;h3 id=&quot;-example-linear-least-squares-fit&quot;&gt;ðŸ”¸ Example (Linear Least Squares Fit):&lt;/h3&gt;

&lt;p&gt;Data: $(1,2)$, $(2,3)$, $(3,5)$&lt;/p&gt;

&lt;p&gt;Compute:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\sum x = 6$, $\sum y = 10$, $\sum xy = 23$, $\sum x^2 = 14$, $n=3$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Normal equations:&lt;/p&gt;

\[10 = 6m + 3c \\
23 = 14m + 6c\]

&lt;p&gt;Solving gives: $m = 1.5$, $c = 0.333$&lt;/p&gt;

&lt;p&gt;Best fit: $y = 1.5x + 0.333$&lt;/p&gt;

&lt;h3 id=&quot;-polynomial-least-squares&quot;&gt;ðŸ”¸ Polynomial Least Squares:&lt;/h3&gt;

&lt;p&gt;Minimize the sum of squares for a polynomial:&lt;/p&gt;

\[y = a_0 + a_1x + a_2x^2 + \dots + a_nx^n\]

&lt;p&gt;Use matrix techniques to solve the normal equations.&lt;/p&gt;

&lt;h3 id=&quot;-advantages&quot;&gt;ðŸ”¸ Advantages:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Simple to implement&lt;/li&gt;
  &lt;li&gt;Well-studied and robust&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-limitations&quot;&gt;ðŸ”¸ Limitations:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Sensitive to outliers&lt;/li&gt;
  &lt;li&gt;Overfitting with high-degree polynomials&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-summary-table&quot;&gt;ðŸ“‹ Summary Table&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Concept&lt;/th&gt;
      &lt;th&gt;Domain&lt;/th&gt;
      &lt;th&gt;Input Data Range&lt;/th&gt;
      &lt;th&gt;Output Estimate&lt;/th&gt;
      &lt;th&gt;Confidence&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Interpolation&lt;/td&gt;
      &lt;td&gt;Within data&lt;/td&gt;
      &lt;td&gt;[x_min, x_max]&lt;/td&gt;
      &lt;td&gt;Estimated y&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Extrapolation&lt;/td&gt;
      &lt;td&gt;Outside data&lt;/td&gt;
      &lt;td&gt;x &amp;lt; x_min or x &amp;gt; x_max&lt;/td&gt;
      &lt;td&gt;Forecasted y&lt;/td&gt;
      &lt;td&gt;Lower&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Curve Fitting&lt;/td&gt;
      &lt;td&gt;Entire dataset&lt;/td&gt;
      &lt;td&gt;All data points&lt;/td&gt;
      &lt;td&gt;Best-fit curve (y vs x)&lt;/td&gt;
      &lt;td&gt;Varies&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Least Squares&lt;/td&gt;
      &lt;td&gt;Numerical method&lt;/td&gt;
      &lt;td&gt;All data points&lt;/td&gt;
      &lt;td&gt;Curve parameters (e.g. m, c)&lt;/td&gt;
      &lt;td&gt;Depends on data&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-further-reading&quot;&gt;ðŸ” Further Reading&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Numerical Analysis by R.L. Burden and J.D. Faires&lt;/li&gt;
  &lt;li&gt;Curve Fitting for Programmers (NumPy, SciPy)&lt;/li&gt;
  &lt;li&gt;Applied Regression Analysis&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;solution-of-first-order-differential-equation-using-runge-kutta-method&quot;&gt;Solution of First Order Differential Equation using Runge-Kutta Method&lt;/h1&gt;

&lt;p&gt;The numerical solution of &lt;strong&gt;first-order differential equations&lt;/strong&gt; plays a crucial role across science and engineering. While many analytical methods exist, they are often limited to relatively simple equations. As a result, numerical methods have become indispensable tools for approximating solutions.&lt;/p&gt;

&lt;p&gt;Several methods are available for numerically solving first-order ordinary differential equations (ODEs):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Eulerâ€™s Method&lt;/strong&gt;: The simplest method, based on a first-order Taylor expansion. It is easy to implement but often suffers from large truncation errors, especially over larger step sizes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Improved Eulerâ€™s Method (Heunâ€™s Method)&lt;/strong&gt;: An enhancement over Eulerâ€™s method, reducing errors by using an averaged slope.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Taylor Series Methods&lt;/strong&gt;: These methods provide high accuracy but require the calculation of higher-order derivatives, making them computationally intensive.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Runge-Kutta Methods&lt;/strong&gt;: A family of iterative methods that achieve higher accuracy without requiring higher derivatives. They are the most widely used in practice due to their balance between simplicity, accuracy, and computational efficiency.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Among these, the &lt;strong&gt;Runge-Kutta methods&lt;/strong&gt; stand out as the most popular because:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;They do not require the explicit computation of higher derivatives (unlike Taylor series methods).&lt;/li&gt;
  &lt;li&gt;They can achieve high-order accuracy with relatively simple formulas.&lt;/li&gt;
  &lt;li&gt;They are robust and flexible, applicable to a wide variety of differential equations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Runge-Kutta family includes methods of various orders:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First-Order Runge-Kutta (RK1)&lt;/strong&gt;: Equivalent to Eulerâ€™s method.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second-Order Runge-Kutta (RK2)&lt;/strong&gt;: Also known as the Improved Euler or Heunâ€™s method, offering better accuracy.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Third-Order Runge-Kutta (RK3)&lt;/strong&gt;: Provides intermediate accuracy but is less commonly used.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fourth-Order Runge-Kutta (RK4)&lt;/strong&gt;: The most popular method, offering excellent accuracy with manageable computational complexity.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Higher-Order Runge-Kutta Methods&lt;/strong&gt;: Methods of order five and above exist (such as the Runge-Kutta-Fehlberg and Dormand-Prince methods) but are typically used for adaptive step-size control in more advanced applications.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;fourth-order-runge-kutta-method-rk4&quot;&gt;Fourth-Order Runge-Kutta Method (RK4)&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Runge-Kutta methods&lt;/strong&gt; are a family of iterative methods for approximating the solution of &lt;strong&gt;first-order ordinary differential equations (ODEs)&lt;/strong&gt; of the form:&lt;/p&gt;

\[\frac{dy}{dx} = f(x, y), \quad y(x_0) = y_0\]

&lt;p&gt;Suppose we wish to find \(y(x)\) at \(x = x_0 + h\) given \(y(x_0) = y_0\). The RK4 method uses the following steps:&lt;/p&gt;

&lt;h3 id=&quot;formulae&quot;&gt;Formulae:&lt;/h3&gt;

&lt;p&gt;Compute intermediate slopes:&lt;/p&gt;

\[\begin{aligned}
k_1 &amp;amp;= h f(x_0, y_0) \\
k_2 &amp;amp;= h f\left(x_0 + \frac{h}{2}, y_0 + \frac{k_1}{2}\right) \\
k_3 &amp;amp;= h f\left(x_0 + \frac{h}{2}, y_0 + \frac{k_2}{2}\right) \\
k_4 &amp;amp;= h f(x_0 + h, y_0 + k_3)
\end{aligned}\]

&lt;p&gt;Then, update the solution:&lt;/p&gt;

\[y(x_0+h) = y_0 + \frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4)\]

&lt;hr /&gt;

&lt;h2 id=&quot;step-by-step-procedure&quot;&gt;Step-by-Step Procedure&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Start with initial conditions \((x_0, y_0)\).&lt;/li&gt;
  &lt;li&gt;Choose a step size \(h\).&lt;/li&gt;
  &lt;li&gt;Compute \(k_1, k_2, k_3, k_4\) using the given \(f(x, y)\).&lt;/li&gt;
  &lt;li&gt;Find the next value \(y_1\) using the weighted average.&lt;/li&gt;
  &lt;li&gt;Update \(x\) to \(x_1 = x_0 + h\).&lt;/li&gt;
  &lt;li&gt;Repeat the process as needed.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-1&quot;&gt;Example 1&lt;/h2&gt;

&lt;h3 id=&quot;problem&quot;&gt;Problem:&lt;/h3&gt;

&lt;p&gt;Solve&lt;/p&gt;

\[\frac{dy}{dx} = x + y, \quad y(0) = 1\]

&lt;p&gt;Find \(y(0.1)\) using RK4 with step size \(h = 0.1\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;solution&quot;&gt;Solution:&lt;/h3&gt;

&lt;p&gt;Given:&lt;/p&gt;

\[f(x,y) = x + y\]

&lt;p&gt;Initial conditions:&lt;/p&gt;

\[x_0 = 0, \quad y_0 = 1, \quad h = 0.1\]

&lt;p&gt;Compute:&lt;/p&gt;

\[\begin{aligned}
k_1 &amp;amp;= h f(x_0, y_0) = 0.1 (0 + 1) = 0.1 \\
k_2 &amp;amp;= h f\left(x_0 + \frac{h}{2}, y_0 + \frac{k_1}{2}\right) = 0.1 (0.05 + 1.05) = 0.1(1.1) = 0.11 \\
k_3 &amp;amp;= h f\left(x_0 + \frac{h}{2}, y_0 + \frac{k_2}{2}\right) = 0.1 (0.05 + 1.055) = 0.1(1.105) = 0.1105 \\
k_4 &amp;amp;= h f(x_0 + h, y_0 + k_3) = 0.1 (0.1 + 1.1105) = 0.1(1.2105) = 0.12105
\end{aligned}\]

&lt;p&gt;Now:&lt;/p&gt;

\[\begin{aligned}
y(0.1) &amp;amp;= y_0 + \frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4) \\
&amp;amp;= 1 + \frac{1}{6}(0.1 + 2(0.11) + 2(0.1105) + 0.12105) \\
&amp;amp;= 1 + \frac{1}{6}(0.1 + 0.22 + 0.221 + 0.12105) \\
&amp;amp;= 1 + \frac{1}{6}(0.66205) \\
&amp;amp;= 1 + 0.11034 \\
&amp;amp;\approx 1.11034
\end{aligned}\]

&lt;p&gt;Thus, \(y(0.1) \approx 1.11034\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-2&quot;&gt;Example 2&lt;/h2&gt;

&lt;h3 id=&quot;problem-1&quot;&gt;Problem:&lt;/h3&gt;

&lt;p&gt;Solve&lt;/p&gt;

\[\frac{dy}{dx} = y - x^2 + 1, \quad y(0) = 0.5\]

&lt;p&gt;Find \(y(0.2)\) using RK4 with step size \(h = 0.2\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;solution-1&quot;&gt;Solution:&lt;/h3&gt;

&lt;p&gt;Given:&lt;/p&gt;

\[f(x,y) = y - x^2 + 1\]

&lt;p&gt;Initial conditions:&lt;/p&gt;

\[x_0 = 0, \quad y_0 = 0.5, \quad h = 0.2\]

&lt;p&gt;Compute:&lt;/p&gt;

\[\begin{aligned}
k_1 &amp;amp;= h f(x_0, y_0) = 0.2 (0.5 - 0^2 + 1) = 0.2(1.5) = 0.3 \\
k_2 &amp;amp;= h f\left(x_0 + \frac{h}{2}, y_0 + \frac{k_1}{2}\right) = 0.2\left( (0.5 + 0.15) - (0.1)^2 + 1 \right) \\
&amp;amp;= 0.2 (0.65 - 0.01 + 1) = 0.2(1.64) = 0.328 \\
k_3 &amp;amp;= h f\left(x_0 + \frac{h}{2}, y_0 + \frac{k_2}{2}\right) = 0.2 \left( (0.5 + 0.164) - (0.1)^2 + 1 \right) \\
&amp;amp;= 0.2(1.654) = 0.3308 \\
k_4 &amp;amp;= h f(x_0 + h, y_0 + k_3) = 0.2 \left( (0.5 + 0.3308) - (0.2)^2 + 1 \right) \\
&amp;amp;= 0.2(0.8308 - 0.04 + 1) = 0.2(1.7908) = 0.35816
\end{aligned}\]

&lt;p&gt;Now:&lt;/p&gt;

\[\begin{aligned}
y(0.2) &amp;amp;= y_0 + \frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4) \\
&amp;amp;= 0.5 + \frac{1}{6}(0.3 + 2(0.328) + 2(0.3308) + 0.35816) \\
&amp;amp;= 0.5 + \frac{1}{6}(0.3 + 0.656 + 0.6616 + 0.35816) \\
&amp;amp;= 0.5 + \frac{1}{6}(1.97576) \\
&amp;amp;= 0.5 + 0.32929 \\
&amp;amp;= 0.82929
\end{aligned}\]

&lt;p&gt;Thus, \(y(0.2) \approx 0.82929\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;advantages-of-runge-kutta-method&quot;&gt;Advantages of Runge-Kutta Method&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;High accuracy with relatively fewer steps.&lt;/li&gt;
  &lt;li&gt;No need to calculate higher derivatives (unlike Taylor series method).&lt;/li&gt;
  &lt;li&gt;Widely applicable to a variety of ODE problems.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;hr /&gt;

&lt;h1 id=&quot;finite-difference-method-fdm&quot;&gt;Finite Difference Method (FDM)&lt;/h1&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Finite Difference Method (FDM)&lt;/strong&gt; is one of the most widely used numerical techniques for solving differential equations, particularly when analytical solutions are difficult or impossible to obtain.&lt;/p&gt;

&lt;p&gt;Compared to other methods:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Simplicity&lt;/strong&gt;: FDM directly discretizes the differential equations into algebraic equations, making it easy to implement.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Flexibility&lt;/strong&gt;: It can handle complex boundary conditions effectively.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Efficiency&lt;/strong&gt;: It is computationally faster for structured grids and simple geometries.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Accuracy Control&lt;/strong&gt;: The accuracy can be systematically improved by refining the grid (reducing step size).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unlike methods like the &lt;strong&gt;Taylor series expansion&lt;/strong&gt; (which require computation of higher-order derivatives) or the &lt;strong&gt;Runge-Kutta methods&lt;/strong&gt; (which approximate solutions point by point), FDM transforms the entire differential equation into a system of algebraic equations across a discretized domain, providing a &lt;strong&gt;global&lt;/strong&gt; numerical solution.&lt;/p&gt;

&lt;p&gt;Thus, FDM is particularly powerful for solving:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Boundary Value Problems&lt;/strong&gt; (BVPs)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Partial Differential Equations&lt;/strong&gt; (PDEs)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Time-dependent problems&lt;/strong&gt; (in combination with time discretization)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;working-principle&quot;&gt;Working Principle&lt;/h2&gt;

&lt;p&gt;The core idea of the Finite Difference Method is to replace &lt;strong&gt;derivatives&lt;/strong&gt; by &lt;strong&gt;finite difference approximations&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;For a function \(y(x)\), the derivatives are approximated as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First Derivative&lt;/strong&gt; (Forward Difference):
\(\frac{dy}{dx}\Bigg|_{x=x_i} \approx \frac{y(x_{i+1}) - y(x_i)}{h}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;First Derivative&lt;/strong&gt; (Backward Difference):
\(\frac{dy}{dx}\Bigg|_{x=x_i} \approx \frac{y(x_i) - y(x_{i-1})}{h}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;First Derivative&lt;/strong&gt; (Central Difference):
\(\frac{dy}{dx}\Bigg|_{x=x_i} \approx \frac{y(x_{i+1}) - y(x_{i-1})}{2h}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second Derivative&lt;/strong&gt; (Central Difference):
\(\frac{d^2y}{dx^2}\Bigg|_{x=x_i} \approx \frac{y(x_{i+1}) - 2y(x_i) + y(x_{i-1})}{h^2}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(h\) is the step size between adjacent points: \(h = x_{i+1} - x_i\).&lt;/li&gt;
  &lt;li&gt;\(x_i\) are the grid points at which we compute the solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Basic steps:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Discretize the domain into a set of points.&lt;/li&gt;
  &lt;li&gt;Replace derivatives in the differential equation using finite differences.&lt;/li&gt;
  &lt;li&gt;Form a system of algebraic equations.&lt;/li&gt;
  &lt;li&gt;Solve the system to approximate the values of the unknown function at the grid points.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;simple-example&quot;&gt;Simple Example&lt;/h2&gt;

&lt;h3 id=&quot;example-solve&quot;&gt;Example: Solve&lt;/h3&gt;

&lt;p&gt;\(\frac{d^2y}{dx^2} = -2, \quad 0 \leq x \leq 1\)
with boundary conditions:&lt;/p&gt;

\[y(0) = 0, \quad y(1) = 0\]

&lt;hr /&gt;

&lt;h3 id=&quot;step-1-discretize-the-domain&quot;&gt;Step 1: Discretize the domain&lt;/h3&gt;

&lt;p&gt;Letâ€™s divide the domain into 4 equal intervals (5 points):&lt;/p&gt;

\[h = \frac{1-0}{4} = 0.25\]

&lt;p&gt;Grid points:&lt;/p&gt;

\[x_0 = 0, \quad x_1 = 0.25, \quad x_2 = 0.5, \quad x_3 = 0.75, \quad x_4 = 1\]

&lt;p&gt;Given: \(y(0) = 0\), \(y(1) = 0\)&lt;/p&gt;

&lt;p&gt;We need to find \(y_1, y_2, y_3\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;step-2-replace-derivatives-using-finite-difference-approximation&quot;&gt;Step 2: Replace derivatives using finite difference approximation&lt;/h3&gt;

&lt;p&gt;Using central difference for the second derivative:&lt;/p&gt;

\[\frac{y_{i+1} - 2y_i + y_{i-1}}{h^2} = -2\]

&lt;p&gt;Multiply throughout by \(h^2\):&lt;/p&gt;

\[y_{i+1} - 2y_i + y_{i-1} = -2h^2\]

&lt;p&gt;Since \(h = 0.25\), we have:&lt;/p&gt;

\[h^2 = 0.0625\]

&lt;p&gt;Thus:&lt;/p&gt;

\[y_{i+1} - 2y_i + y_{i-1} = -0.125\]

&lt;hr /&gt;

&lt;h3 id=&quot;step-3-set-up-equations&quot;&gt;Step 3: Set up equations&lt;/h3&gt;

&lt;p&gt;For each interior point:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;At \(x_1\): 
\(y_2 - 2y_1 + y_0 = -0.125\)
Since \(y_0 = 0\), it simplifies to:
\(y_2 - 2y_1 = -0.125\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;At \(x_2\):
\(y_3 - 2y_2 + y_1 = -0.125\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;At \(x_3\):
\(y_4 - 2y_3 + y_2 = -0.125\)
Since \(y_4 = 0\), it simplifies to:
\(-2y_3 + y_2 = -0.125\)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;step-4-solve-the-system&quot;&gt;Step 4: Solve the system&lt;/h3&gt;

&lt;p&gt;System of equations:&lt;/p&gt;

\[\begin{aligned}
-2y_1 + y_2 &amp;amp;= -0.125 \quad (1) \\
y_1 - 2y_2 + y_3 &amp;amp;= -0.125 \quad (2) \\
y_2 - 2y_3 &amp;amp;= -0.125 \quad (3)
\end{aligned}\]

&lt;p&gt;You can solve this system using substitution, matrix methods, or a simple calculator to find \(y_1, y_2, y_3\).&lt;/p&gt;

&lt;hr /&gt;
&lt;hr /&gt;

&lt;h1 id=&quot;numerical-integration-trapezoidal-rule-and-simpsons-rule&quot;&gt;Numerical Integration: Trapezoidal Rule and Simpsonâ€™s Rule&lt;/h1&gt;

&lt;p&gt;In many practical situations, finding the exact value of a definite integral:&lt;/p&gt;

\[\int_a^b f(x)\,dx\]

&lt;p&gt;is either very difficult or impossible analytically.&lt;br /&gt;
&lt;strong&gt;Numerical integration (or quadrature)&lt;/strong&gt; techniques provide approximate methods to evaluate such integrals.&lt;/p&gt;

&lt;p&gt;Two of the most popular and widely used methods are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Trapezoidal Rule&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Simpsonâ€™s Rule&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both methods replace the function with simple polynomials (linear for trapezoidal, quadratic for Simpsonâ€™s) and then integrate the approximations exactly.&lt;/p&gt;

&lt;h2 id=&quot;trapezoidal-rule&quot;&gt;Trapezoidal Rule&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Trapezoidal Rule&lt;/strong&gt; approximates the area under a curve by dividing it into &lt;strong&gt;trapezoids&lt;/strong&gt; instead of rectangles.&lt;/p&gt;

&lt;p&gt;Suppose we want to evaluate:&lt;/p&gt;

\[I = \int_a^b f(x)\,dx\]

&lt;p&gt;Divide the interval \([a, b]\) into \(n\) equal subintervals, each of width:&lt;/p&gt;

\[h = \frac{b-a}{n}\]

&lt;p&gt;The trapezoidal approximation is:&lt;/p&gt;

\[I \approx \frac{h}{2} \left[ f(x_0) + 2f(x_1) + 2f(x_2) + \cdots + 2f(x_{n-1}) + f(x_n) \right]\]

&lt;p&gt;where:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[x_0 = a\]
  &lt;/li&gt;
  &lt;li&gt;
\[x_n = b\]
  &lt;/li&gt;
  &lt;li&gt;\(x_i = a + ih\) for \(i = 1, 2, \ldots, n-1\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;error-estimate&quot;&gt;Error Estimate&lt;/h3&gt;

&lt;p&gt;The error \(E_T\) in the trapezoidal rule is approximately:&lt;/p&gt;

\[E_T = -\frac{(b-a)^3}{12n^2} f&apos;&apos;(\xi)\]

&lt;p&gt;for some \(\xi\) in \((a,b)\).&lt;br /&gt;
Thus, the error decreases quadratically as \(n\) increases.&lt;/p&gt;

&lt;h2 id=&quot;simpsons-rule&quot;&gt;Simpsonâ€™s Rule&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Simpsonâ€™s Rule&lt;/strong&gt; approximates the function by a &lt;strong&gt;second-degree polynomial (parabola)&lt;/strong&gt; through each set of three points and integrates the parabola exactly.&lt;/p&gt;

&lt;p&gt;Divide \([a, b]\) into an &lt;strong&gt;even&lt;/strong&gt; number \(n\) of subintervals (important: \(n\) must be even), each of width:&lt;/p&gt;

\[h = \frac{b-a}{n}\]

&lt;p&gt;The Simpsonâ€™s 1/3 Rule formula is:&lt;/p&gt;

\[I \approx \frac{h}{3} \left[ f(x_0) + 4f(x_1) + 2f(x_2) + 4f(x_3) + 2f(x_4) + \cdots + 2f(x_{n-2}) + 4f(x_{n-1}) + f(x_n) \right]\]

&lt;p&gt;Notice the pattern:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Coefficient 4 for odd-indexed points&lt;/li&gt;
  &lt;li&gt;Coefficient 2 for even-indexed points (except first and last)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;error-estimate-1&quot;&gt;Error Estimate&lt;/h3&gt;

&lt;p&gt;The error \(E_S\) in Simpsonâ€™s Rule is approximately:&lt;/p&gt;

\[E_S = -\frac{(b-a)^5}{180n^4} f^{(4)}(\xi)\]

&lt;p&gt;for some \(\xi\) in \((a,b)\).&lt;br /&gt;
Thus, Simpsonâ€™s rule is much more accurate than the trapezoidal rule for smooth functions â€” error decreases with \(n^4\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;simple-examples&quot;&gt;Simple Examples&lt;/h2&gt;

&lt;h3 id=&quot;example-1-trapezoidal-rule&quot;&gt;Example 1: Trapezoidal Rule&lt;/h3&gt;

&lt;p&gt;Approximate:&lt;/p&gt;

\[\int_0^1 x^2\,dx\]

&lt;p&gt;using \(n=2\) intervals.&lt;/p&gt;

&lt;h4 id=&quot;step-1-divide-the-interval&quot;&gt;Step 1: Divide the interval&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
\[h = \frac{1-0}{2} = 0.5\]
  &lt;/li&gt;
  &lt;li&gt;Points: \(x_0 = 0\), \(x_1 = 0.5\), \(x_2 = 1\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-2-evaluate-the-function&quot;&gt;Step 2: Evaluate the function&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
\[f(0) = 0^2 = 0\]
  &lt;/li&gt;
  &lt;li&gt;
\[f(0.5) = 0.25\]
  &lt;/li&gt;
  &lt;li&gt;
\[f(1) = 1\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-3-apply-trapezoidal-formula&quot;&gt;Step 3: Apply trapezoidal formula&lt;/h4&gt;

\[I \approx \frac{0.5}{2} \left[ 0 + 2(0.25) + 1 \right]
= 0.25 \times (1.5)
= 0.375\]

&lt;h4 id=&quot;exact-answer&quot;&gt;Exact answer&lt;/h4&gt;

&lt;p&gt;The exact value is:&lt;/p&gt;

\[\int_0^1 x^2\,dx = \frac{1}{3} \approx 0.3333\]

&lt;p&gt;Thus, trapezoidal rule gives a slightly overestimated result.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;example-2-simpsons-rule&quot;&gt;Example 2: Simpsonâ€™s Rule&lt;/h3&gt;

&lt;p&gt;Approximate:&lt;/p&gt;

\[\int_0^1 x^2\,dx\]

&lt;p&gt;using \(n=2\) intervals.&lt;/p&gt;

&lt;h4 id=&quot;step-1-divide-the-interval-1&quot;&gt;Step 1: Divide the interval&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
\[h = 0.5\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-2-evaluate-the-function-1&quot;&gt;Step 2: Evaluate the function&lt;/h4&gt;

&lt;p&gt;Already calculated above:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[f(0) = 0\]
  &lt;/li&gt;
  &lt;li&gt;
\[f(0.5) = 0.25\]
  &lt;/li&gt;
  &lt;li&gt;
\[f(1) = 1\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;step-3-apply-simpsons-formula&quot;&gt;Step 3: Apply Simpsonâ€™s formula&lt;/h4&gt;

\[I \approx \frac{0.5}{3} \left[ 0 + 4(0.25) + 1 \right]
= \frac{0.5}{3} \times (2)
= \frac{1}{3}
= 0.3333\]

&lt;p&gt;Thus, Simpsonâ€™s rule gives the exact value for polynomials of degree â‰¤ 3.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;summary-table&quot;&gt;Summary Table&lt;/h1&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Feature&lt;/th&gt;
      &lt;th&gt;Trapezoidal Rule&lt;/th&gt;
      &lt;th&gt;Simpsonâ€™s Rule&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Approximation&lt;/td&gt;
      &lt;td&gt;Straight line&lt;/td&gt;
      &lt;td&gt;Parabola&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Accuracy&lt;/td&gt;
      &lt;td&gt;\(O(h^2)\)&lt;/td&gt;
      &lt;td&gt;\(O(h^4)\)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Grid requirement&lt;/td&gt;
      &lt;td&gt;Any number of intervals&lt;/td&gt;
      &lt;td&gt;Even number of intervals&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;When preferred&lt;/td&gt;
      &lt;td&gt;Quick estimate, rough accuracy&lt;/td&gt;
      &lt;td&gt;Higher precision with smooth functions&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">Eigenvalues and eigenvectors play a central role in linear algebra, with wide applications in physics, engineering, and data science. They help understand the action of a linear transformation in a given vector space.</summary></entry><entry><title type="html">Image Processing: Eigenvalues and Eigenvectors</title><link href="http://localhost:4000/SKMU/lecture/2025/04/17/Eigev-Image.html" rel="alternate" type="text/html" title="Image Processing: Eigenvalues and Eigenvectors" /><published>2025-04-17T09:47:26+05:30</published><updated>2025-04-17T09:47:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/04/17/Eigev-Image</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/04/17/Eigev-Image.html">&lt;h2 id=&quot;-objective&quot;&gt;ðŸ§  Objective&lt;/h2&gt;
&lt;p&gt;This lecture explores the application of &lt;strong&gt;eigenvalues&lt;/strong&gt; and &lt;strong&gt;eigenvectors&lt;/strong&gt; in image processing using &lt;strong&gt;Principal Component Analysis (PCA)&lt;/strong&gt;. We will:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understand PCA and its reliance on eigen decomposition.&lt;/li&gt;
  &lt;li&gt;Load and process an image.&lt;/li&gt;
  &lt;li&gt;Use PCA to compress and reconstruct the image.&lt;/li&gt;
  &lt;li&gt;Visualize the effect of PCA using eigenvectors.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-prerequisites&quot;&gt;ðŸ“¦ Prerequisites&lt;/h2&gt;
&lt;p&gt;Install the following Python packages if you havenâ€™t already:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip &lt;span class=&quot;nb&quot;&gt;install &lt;/span&gt;numpy opencv-python matplotlib
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ï¸-step-1-load-and-convert-image-to-grayscale&quot;&gt;ðŸ–¼ï¸ Step 1: Load and Convert Image to Grayscale&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;cv2&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load the image in grayscale mode
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imread&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;img.jpg&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IMREAD_GRAYSCALE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;raise&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;FileNotFoundError&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Image not found. Please check the filename and path.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cv2.imread()&lt;/code&gt; reads the image file.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cv2.IMREAD_GRAYSCALE&lt;/code&gt; loads it in grayscale (single-channel image).&lt;/li&gt;
  &lt;li&gt;We raise an error if the file is not found to prevent further issues.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-2-normalize-and-reshape-the-image&quot;&gt;ðŸ”„ Step 2: Normalize and Reshape the Image&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;255.0&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Normalize pixel values between 0 and 1
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original_shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Original image shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original_shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Normalization makes the data suitable for numerical computations.&lt;/li&gt;
  &lt;li&gt;The shape is stored to understand the structure (rows Ã— columns).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-3-center-the-data-zero-mean&quot;&gt;ðŸŽ¯ Step 3: Center the Data (Zero Mean)&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Mean of each column
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centered_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Centering
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;PCA requires the data to be centered (zero mean).&lt;/li&gt;
  &lt;li&gt;We subtract the mean of each column (each pixel column).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-4-compute-covariance-matrix&quot;&gt;ðŸ“ Step 4: Compute Covariance Matrix&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cov_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cov&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centered_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rowvar&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Covariance matrix shows how features vary together.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rowvar=False&lt;/code&gt;: treats rows as samples and columns as features.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-5-eigen-decomposition&quot;&gt;ðŸ§® Step 5: Eigen Decomposition&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;eigenvalues&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigenvectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cov_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;np.linalg.eigh()&lt;/code&gt; is used for symmetric matrices (like covariance matrices).&lt;/li&gt;
  &lt;li&gt;It returns:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;eigenvalues&lt;/strong&gt;: magnitude of variance in each principal direction.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;eigenvectors&lt;/strong&gt;: directions of maximum variance.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-6-sort-eigenvalues-and-eigenvectors&quot;&gt;ðŸ”¢ Step 6: Sort Eigenvalues and Eigenvectors&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigenvalues&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Descending order
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Reorder eigenvalues and eigenvectors
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eigenvalues&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigenvalues&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;eigenvectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigenvectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;PCA uses components with the highest eigenvalues.&lt;/li&gt;
  &lt;li&gt;We sort in descending order to retain most significant components first.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ï¸-step-7-project-data-to-lower-dimensions&quot;&gt;âœ‚ï¸ Step 7: Project Data to Lower Dimensions&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Number of principal components
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;centered_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigenvectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Project the centered image onto top &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_components&lt;/code&gt; eigenvectors.&lt;/li&gt;
  &lt;li&gt;This step compresses the image data.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-8-reconstruct-the-image&quot;&gt;ðŸ” Step 8: Reconstruct the Image&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;reconstructed_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eigenvectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;We reverse the projection and add the mean back to approximate the original image.&lt;/li&gt;
  &lt;li&gt;The quality depends on how many components we retained.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-step-9-display-original-and-reconstructed-images&quot;&gt;ðŸ“Š Step 9: Display Original and Reconstructed Images&lt;/h2&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Original Image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;gray&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;f&quot;Reconstructed Image (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_components&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; components)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reconstructed_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;gray&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib&lt;/code&gt; is used to plot both images.&lt;/li&gt;
  &lt;li&gt;You can visually compare original vs compressed output.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-key-concepts-recap&quot;&gt;ðŸ“Œ Key Concepts Recap&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Concept&lt;/th&gt;
      &lt;th&gt;Description&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Eigenvalue&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Measure of variance in the data in the direction of its corresponding eigenvector.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Eigenvector&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;A principal axis in the data space â€” direction of maximum variance.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Covariance Matrix&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Square matrix showing covariance (interdependence) between features.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;PCA&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Reduces the dimensions of data using eigen decomposition while preserving the most variance.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-visualization-of-compression&quot;&gt;ðŸ” Visualization of Compression&lt;/h2&gt;
&lt;p&gt;By changing the number of components used (e.g., 10, 20, 100), observe how the quality of reconstruction improves with more components.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-exercises&quot;&gt;ðŸ§ª Exercises&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Try different values of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_components&lt;/code&gt; and plot the error.&lt;/li&gt;
  &lt;li&gt;Apply PCA to a color image by treating each RGB channel separately.&lt;/li&gt;
  &lt;li&gt;Use this technique on image datasets like MNIST or CIFAR-10 for dimensionality reduction.&lt;/li&gt;
  &lt;li&gt;Plot cumulative explained variance using eigenvalues.&lt;/li&gt;
&lt;/ol&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-I" /><summary type="html">ðŸ§  Objective This lecture explores the application of eigenvalues and eigenvectors in image processing using Principal Component Analysis (PCA). We will:</summary></entry><entry><title type="html">Dissertation: N-Interconnected Mass-Spring System</title><link href="http://localhost:4000/SKMU/lecture/2025/04/15/MSC-Disseration-N-Mass-System.html" rel="alternate" type="text/html" title="Dissertation: N-Interconnected Mass-Spring System" /><published>2025-04-15T08:37:26+05:30</published><updated>2025-04-15T08:37:26+05:30</updated><id>http://localhost:4000/SKMU/lecture/2025/04/15/MSC-Disseration-N-Mass-System</id><content type="html" xml:base="http://localhost:4000/SKMU/lecture/2025/04/15/MSC-Disseration-N-Mass-System.html">&lt;div style=&quot;text-align: center;&quot;&gt;
  &lt;img src=&quot;/SKMU/assets/images/Lecture/Spring-Mass.png&quot; alt=&quot;Scattering&quot; class=&quot;my-custom-class&quot; style=&quot;width:70%; height:auto;&quot; /&gt;
&lt;/div&gt;

&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;This project simulates the motion of an &lt;strong&gt;N-body mass-spring system&lt;/strong&gt; where multiple masses are connected via springs and constrained to move &lt;strong&gt;horizontally on a frictionless surface&lt;/strong&gt;. The simulation involves both &lt;strong&gt;numerical solutions to the equations of motion&lt;/strong&gt; and a &lt;strong&gt;graphical animation using PyGame&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The motivation for this study arises from its relevance in:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Understanding lattice vibrations in solid state physics,&lt;/li&gt;
  &lt;li&gt;Modeling mechanical systems in classical dynamics,&lt;/li&gt;
  &lt;li&gt;Exploring numerical ODE solvers and interactive simulation frameworks.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;2-system-description&quot;&gt;2. System Description&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;The system consists of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; identical masses.&lt;/li&gt;
  &lt;li&gt;Each mass is connected to its neighbors using linear springs.&lt;/li&gt;
  &lt;li&gt;The surface is perfectly frictionless, so there is no damping.&lt;/li&gt;
  &lt;li&gt;All masses are initially at rest, and motion is initiated only through initial displacements.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The structure is &lt;strong&gt;linear&lt;/strong&gt;, and &lt;strong&gt;fixed boundary conditions&lt;/strong&gt; are typically assumed at the ends, although this can be generalized.&lt;/p&gt;

&lt;h2 id=&quot;3-assumptions&quot;&gt;3. Assumptions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;All masses \(m\) are &lt;strong&gt;identical&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;All springs have the same spring constant \(k\).&lt;/li&gt;
  &lt;li&gt;Motion is constrained to &lt;strong&gt;1D horizontal motion&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;The springs obey &lt;strong&gt;Hookeâ€™s law&lt;/strong&gt; (linear restoring force).&lt;/li&gt;
  &lt;li&gt;The system starts from &lt;strong&gt;rest&lt;/strong&gt;, i.e., initial velocities are zero.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-mathematical-modeling&quot;&gt;4. Mathematical Modeling&lt;/h2&gt;

&lt;p&gt;For each mass \(i\) (\(1 \leq i \leq n\)), Newtonâ€™s second law gives:&lt;/p&gt;

\[m \frac{d^2 x_i}{dt^2} = -k(x_i - x_{i-1}) + k(x_{i+1} - x_i)\]

&lt;p&gt;Rewriting:&lt;/p&gt;

\[\frac{d^2 x_i}{dt^2} = \frac{k}{m} (x_{i+1} - 2x_i + x_{i-1})\]

&lt;p&gt;This is a system of &lt;strong&gt;coupled second-order ODEs&lt;/strong&gt;, forming a &lt;strong&gt;discrete wave equation&lt;/strong&gt;. Special cases:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For \(i = 1\): left boundary (may be fixed or free),&lt;/li&gt;
  &lt;li&gt;For \(i = n\): right boundary.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This system can be written in matrix form:&lt;/p&gt;

\[\mathbf{M} \ddot{\mathbf{x}} = -\mathbf{Kx}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{x}\) is the position vector,&lt;/li&gt;
  &lt;li&gt;\(\mathbf{M} = m \mathbf{I}\) is the mass matrix,&lt;/li&gt;
  &lt;li&gt;\(\mathbf{K}\) is the stiffness matrix (tridiagonal).&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-numerical-integration&quot;&gt;5. Numerical Integration&lt;/h2&gt;

&lt;p&gt;To solve the equations of motion, we apply numerical methods such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Eulerâ€™s method&lt;/strong&gt; (simplest, not very accurate),&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Verlet integration&lt;/strong&gt; (commonly used in physics),&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;SciPyâ€™s &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;solve_ivp&lt;/code&gt;&lt;/strong&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RK45&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RK23&lt;/code&gt; solvers.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The user inputs initial displacements for each mass, and the system automatically generates:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The stiffness matrix based on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt;,&lt;/li&gt;
  &lt;li&gt;Initial state vectors for position and velocity,&lt;/li&gt;
  &lt;li&gt;Solution over a specified time interval.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-visualization-and-simulation&quot;&gt;6. Visualization and Simulation&lt;/h2&gt;

&lt;h3 id=&quot;61-matplotlib-plot&quot;&gt;6.1 Matplotlib Plot&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;displacement of each mass over time&lt;/strong&gt; is first visualized using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;matplotlib.pyplot&lt;/code&gt;, typically as:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Line plots of \(x_i(t)\) vs time,&lt;/li&gt;
  &lt;li&gt;Optional animation using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FuncAnimation&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;62-pygame-animation&quot;&gt;6.2 PyGame Animation&lt;/h3&gt;

&lt;p&gt;Once the numerical solution is complete, a &lt;strong&gt;PyGame-based animation&lt;/strong&gt; shows the physical behavior:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Masses oscillate horizontally,&lt;/li&gt;
  &lt;li&gt;Springs are drawn as dynamic lines,&lt;/li&gt;
  &lt;li&gt;The background (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;floor.jpg&lt;/code&gt;) is customizable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This animation helps build &lt;strong&gt;intuitive understanding&lt;/strong&gt; of oscillatory motion and energy exchange in coupled systems.&lt;/p&gt;

&lt;h2 id=&quot;7-user-interaction&quot;&gt;7. User Interaction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;The user provides a list of initial positions (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[1.0, -1.5, 0.3]&lt;/code&gt;) to define the system.&lt;/li&gt;
  &lt;li&gt;Each input corresponds to a new mass.&lt;/li&gt;
  &lt;li&gt;The user can customize:
    &lt;ul&gt;
      &lt;li&gt;Background image,&lt;/li&gt;
      &lt;li&gt;Mass and spring appearance,&lt;/li&gt;
      &lt;li&gt;Simulation speed.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;8-applications-and-extensions&quot;&gt;8. Applications and Extensions&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lattice vibrations&lt;/strong&gt;: Ideal for simulating 1D phonons.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Signal propagation&lt;/strong&gt;: Observing how disturbances travel through coupled media.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modes of vibration&lt;/strong&gt;: Visualize normal modes and beat phenomena.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonlinear springs&lt;/strong&gt;: Can be extended by replacing Hookeâ€™s law with nonlinear force models.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;9-files-and-structure&quot;&gt;9. Files and Structure&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mass_spring_simulation.py&lt;/code&gt;: Main simulation script,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;floor.jpg&lt;/code&gt;: Background image (user replaceable),&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;utils.py&lt;/code&gt;: Helper functions for drawing and integration,&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;initial_conditions.txt&lt;/code&gt;: Optional file for storing default states.&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Rajesh Kumar</name></author><category term="SEM-IV" /><summary type="html"></summary></entry></feed>